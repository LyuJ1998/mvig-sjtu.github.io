<html>

<head>
  <meta charset="utf-8">

  <title>Publications | SJTU Machine Vision and Intelligence Group</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
  <meta property="og:title" content="CS348 Computer Vision">
  <meta property="og:url" content="http://yoursite.com/teaching/index.html">
  <meta property="og:site_name" content="SJTU Machine Vision and Intelligence Group">
  <meta property="og:updated_time" content="2017-10-08T15:42:37.720Z">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="CS348 Computer Vision">

  <link rel="alternate" href="/atom.xml" title="SJTU Machine Vision and Intelligence Group" type="application/atom+xml">



  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">
  <link rel="stylesheet" href="/css/styles.css">
  <style type="text/css">
    div.instructorphoto>img {
      width: 150px;
      height: 150px;
      border-radius: 50%;
      align-content: center;
      margin: 50px 50px;
    }

    tr,
    th,
    td {
      align-content: center;
      text-align: center;
    }

    table.member>tbody>tr>td {
      border: none;
    }

    table.member>tbody>tr>th {
      border: none;
    }
  </style>

</head>

<body>
  <nav class="navbar navbar-inverse">
    <div class="container">
      <!-- Brand and toggle get grouped for better mobile display -->
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>

      </div>
      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse" id="main-menu-navbar">
        <!-- <h4 style="font-family:verdana;">Machine Vision and Intelligence Group</h4> -->
        <ul class="nav navbar-nav">
          <li><a class="navbar_brand"><strong>Machine Vision and Intelligence Group
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;</strong></a></li>

          <li><a class="" href="/index.html">Cewu Lu</a></li>

          <li><a class="active" href="/research/index.html">Research</a></li>

          <li><a class="" href="/publications/index.html">Publications</a></li>

          <li><a class="" href="/teaching/index.html">Teaching</a></li>

          <!-- <li><a class="" href="/member/index.html">Member</a></li> -->


        </ul>
      </div>
    </div>
  </nav>

  <header class="article-header">
    <center>
      <table>
        <tr>
          <td><strong>
              <h1>Activity Understanding meets 3D Representation</h1><strong></strong>
            </strong></td>

        </tr>
      </table>
      <h3>PRCV 2018, Talk by Cewu Lu</h3>
      <h3>地点：广州白云国际会议中心，2号楼 2楼汕头厅</h3>
      <h3> 时间：2018年11月24号 16:30-17:00 </h3>
    </center>
  </header>
  <center>
    <table style="width: 80%;">
      <center>
        <h2 style="color: blue;font-weight:bold">三维视觉</h2>
      </center>
      <tr>
        <td style="padding-top: 0px;">
          <img src="../publications/pointSIFT/network.png" width="360">
        </td>
        <td style="padding-top: 0px;">
          <img src="./pointwise/pointwise.png" width="360">
        </td>
        <td style="padding-top: 0px;">
          <img src="./dbnet/dbnet.png" width="360">
        </td>
      </tr>
      <tr>
        <td><a style="font-size:30;font-weight:bold;" href="../publications/pointSIFT.html">pointSIFT</a></td>
        <td><a style="font-size:20;font-weight:bold" href="./pointwise/pointwise.html">Pointwise Rotation-Invariant
            Network</a></td>
        <td><a style="font-size:30;font-weight:bold" href="http://www.dbehavior.net/" target="_blank" rel="external">DBNET</a></td>
      </tr>

      <tr>
        <td><a href="https://github.com/MVIG-SJTU/pointSIFT" target="_blank" rel="external"><i class="fa fa-github" aria-hidden="true"></i> Github </a>
          <a href="https://arxiv.org/abs/1807.00652" target="_blank" rel="external"><i class="fa fa-file-text" aria-hidden="true"></i> paper </a></td>
        <td><a href="https://github.com/qq456cvb/PRIN" target="_blank" rel="external"><i class="fa fa-github" aria-hidden="true"></i>
            Github </a>
          <a href="https://arxiv.org/abs/1811.09361" target="_blank" rel="external"><i class="fa fa-file-text" aria-hidden="true"></i>
            paper </a></td>
        <td><a href="https://github.com/driving-behavior/DBNet" target="_blank" rel="external"><i class="fa fa-github" aria-hidden="true"></i> Dataset </a>
          <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.pdf" target="_blank" rel="external"><i class="fa fa-file-text" aria-hidden="true"></i> paper </a></td>

      </tr>

      <tr style="text-align: left">
        <td style="text-align: left">描述：一个高效且通用的3D点云表征模块<br>
          性能：在S3DIS/Scannet数据集上分别取得<strong>12%/8.4%的IoU相对提高</strong></td>
        <td style="text-align: left">描述：很大程度地解决了点云的旋转不变性表征问题<br>
          性能：旋转过的测试集上获得<strong>20 mIoU</strong>的提高（相对提高55%）
        </td>
        <td style="text-align: left">描述：一个大规模的点云与视频到驾驶行为的端对端数据集
        </td>
      </tr>



    </table>

    <table style="width: 80%;">
      <center>
        <h2 style="color: blue;font-weight:bold">行为理解</h2>
      </center>
      <tr>
        <td style="padding-top: 10px;">
          <img src="./deeprnn/deeprnn.png" width="360">
        </td>
        <td style="padding-top: 10px;">
          <img src="./crowd/crowd.png" width="360">
        </td>
        <td style="padding-top: 10px;">
          <img src="./interactioness/interactioness.png" width="360">
        </td>
      </tr>
      <tr>
        <td><a style="font-size:30;font-weight:bold" href="./deeprnn/deeprnn.html">Deep RNN</a></td>
        <td><a style="font-size:20;font-weight:bold" href="./crowd/crowd.html">AlphaPose beyond COCO</a></td>
        <td><a style="font-size:30;font-weight:bold" href="./interactioness/interactioness.html">Interactiveness Prior</a></td>

      </tr>

      <tr>
        <td><a href="https://github.com/BoPang1996/Deep-RNN-Framework" target="_blank" rel="external"><i class="fa fa-github" aria-hidden="true"></i>
            Github </a>
          <a href="https://arxiv.org/pdf/1811.09961.pdf" target="_blank" rel="external"><i class="fa fa-file-text" aria-hidden="true"></i>
            paper </a></td>
        <td><a href="https://github.com/MVIG-SJTU/AlphaPose" target="_blank" rel="external"><i class="fa fa-github" aria-hidden="true"></i>
            Github </a>
          <a href="https://arxiv.org/pdf/1812.00324.pdf" target="_blank" rel="external"><i class="fa fa-file-text" aria-hidden="true"></i>
            paper </a></td>
        <td><a style="color:grey" href="" target="_blank" rel="external"><i class="fa fa-github" aria-hidden="true"></i>
            Github </a>
          <a href="https://arxiv.org/abs/1811.08264" target="_blank" rel="external"><i class="fa fa-file-text" aria-hidden="true"></i> paper </a></td>
      </tr>

      <tr style="text-align: left">
        <td style="text-align: left">描述：我们提出一套面向视觉问题（比如视频）的 Deep RNN 方案，实现了15层（甚至更深）的RNN叠加<br>
          性能：比起传统LSTM/RNN在四个视觉代表任务上平均<strong>相对提高25%</strong>
        </td>
        <td style="text-align: left">内容：汇报我们alphapose的进展与规划，我讨论了COCO数据中的不足，引出一个新的问题pose estimation in crowd<br>
          性能：提出JC SPPE算法，在hard数据上比<strong>mask-RCNN提高 8.9 mAP</strong>
        </td>

        <td style="text-align: left">描述：针对提出HOI任务一种通用可迁移的Interactioness prior， 展望基于知识引擎的HOI识别系统<br>
          性能：在HICO-DET的多个任务取得<strong>16%-36%的提高</strong>

        </td>
      </tr>

      <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>
      <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
      <script src="/js/script.js"></script>
    </table>
  </center>

  <br><br>
  <br><br>
  <br><br>
  <br><br>
</body>

</html>