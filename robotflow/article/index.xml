<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Articles on RobotFlow</title>
    <link>http://mvig.sjtu.edu.cn/robotflow/article/</link>
    <description>Recent content in Articles on RobotFlow</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Feb 2021 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://mvig.sjtu.edu.cn/robotflow/article/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>All You Need for CMake系列01——Hello CMake!</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9701hello-cmake/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9701hello-cmake/</guid>
      <description>All You Need for CMake系列01——Hello CMake! 安装CMake  对于版本的几个tips  据说3.11后速度获得了极大的提升 Ubuntu 18.04默认的版本是3.10, 所以如果是Ubuntu 18.04及更低版本的同学请自行安装CMake   自行安装的过程比较简单，在官网根据OS版本选一个新的下载安装即可 安装完后cmake -version确认一下版本  一个Hello CMake的例子 准备一个目录，假如是hello-cmake，其文件结构如下:
.├── CMakeLists.txt├── main.cppmain.cpp下面的写如下内容：
#include &amp;lt;iostream&amp;gt; int main(int argc, char *argv[]) { std::cout &amp;lt;&amp;lt; &amp;#34;Hello CMake!&amp;#34; &amp;lt;&amp;lt; std::endl; return 0; } CMakeLists.txt下面的内容如下：
# Set the minimum version of CMake that can be used # To find the cmake version run # $ cmake --version cmake_minimum_required(VERSION 3.</description>
    </item>
    
    <item>
      <title>All You Need for CMake系列02——Hello Headers</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9702hello-headers/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9702hello-headers/</guid>
      <description>All You Need for CMake系列02——Hello Headers 准备代码 代码结构如下：
.├── CMakeLists.txt├── include│ └── Hello.h└── src├── Hello.cpp└── main.cpp这是一个经典结构，moveit里面单独的包都是用这种方式写的。
Hello.h里内容如下：
#ifndef __HELLO_H__ #define __HELLO_H__  class Hello { public: void print(); }; #endif Hello.cpp里内容如下：
#include &amp;lt;iostream&amp;gt; #include &amp;#34;Hello.h&amp;#34; void Hello::print() { std::cout &amp;lt;&amp;lt; &amp;#34;Hello Headers!&amp;#34; &amp;lt;&amp;lt; std::endl; } main.cpp
#include &amp;#34;Hello.h&amp;#34; int main(int argc, char *argv[]) { Hello hi; hi.print(); return 0; } CMakeLists.txt
cmake_minimum_required(VERSION 3.5)project (hello_headers)# Create a sources variable with a link to all cpp files to compile set(SOURCES src/Hello.</description>
    </item>
    
    <item>
      <title>All You Need for CMake系列03——Static Library</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9703static-library/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9703static-library/</guid>
      <description>All You Need for CMake系列03——Static Library 准备代码 代码结构如下：
.├── CMakeLists.txt├── include│ └── static│ └── Hello.h└── src├── Hello.cpp└── main.cpp这是一个经典结构，moveit里面单独的包都是用这种方式写的。
Hello.h里内容如下：
#ifndef __HELLO_H__ #define __HELLO_H__  class Hello { public: void print(); }; #endif Hello.cpp里内容如下：
#include &amp;lt;iostream&amp;gt; #include &amp;#34;static/Hello.h&amp;#34; void Hello::print() { std::cout &amp;lt;&amp;lt; &amp;#34;Hello Static Library!&amp;#34; &amp;lt;&amp;lt; std::endl; } main.cpp
#include &amp;#34;static/Hello.h&amp;#34; int main(int argc, char *argv[]) { Hello hi; hi.print(); return 0; } CMakeLists.</description>
    </item>
    
    <item>
      <title>All You Need for CMake系列04——Shared Library</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9704shared-library/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9704shared-library/</guid>
      <description>All You Need for CMake系列04——Shared Library 准备代码 代码结构如下：
.├── CMakeLists.txt├── include│ └── shared│ └── Hello.h└── src├── Hello.cpp└── main.cpp这是一个经典结构，moveit里面单独的包都是用这种方式写的。
Hello.h里内容如下：
#ifndef __HELLO_H__ #define __HELLO_H__  class Hello { public: void print(); }; #endif Hello.cpp里内容如下：
#include &amp;lt;iostream&amp;gt; #include &amp;#34;shared/Hello.h&amp;#34; void Hello::print() { std::cout &amp;lt;&amp;lt; &amp;#34;Hello Shared Library!&amp;#34; &amp;lt;&amp;lt; std::endl; } main.cpp
#include &amp;#34;shared/Hello.h&amp;#34; int main(int argc, char *argv[]) { Hello hi; hi.print(); return 0; } CMakeLists.</description>
    </item>
    
    <item>
      <title>All You Need for CMake系列05——Installing</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9705installing/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9705installing/</guid>
      <description>All You Need for CMake系列05——Installing 准备代码 代码结构如下：
.├── cmake-examples.conf├── CMakeLists.txt├── include│ └── installing│ └── Hello.h└── src├── Hello.cpp└── main.cpp相较于之前，多了一个cmake-examples.conf文件，这个是用来配置一些cmake选项的。之前的shared/static改成了installing，这是强调一下是不是动态/静态lib跟目录结构没关系，只跟下面的CMakeLists文件的写法有关。
Hello.h里内容如下：
#ifndef __HELLO_H__ #define __HELLO_H__  class Hello { public: void print(); }; #endif Hello.cpp里内容如下：
#include &amp;lt;iostream&amp;gt; #include &amp;#34;installing/Hello.h&amp;#34; void Hello::print() { std::cout &amp;lt;&amp;lt; &amp;#34;Hello Install!&amp;#34; &amp;lt;&amp;lt; std::endl; } main.cpp
#include &amp;#34;installing/Hello.h&amp;#34; int main(int argc, char *argv[]) { Hello hi; hi.print(); return 0; } CMakeLists.</description>
    </item>
    
    <item>
      <title>All You Need for CMake系列06——Build Type</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9706build-type/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9706build-type/</guid>
      <description>All You Need for CMake系列06——Build Type 准备代码 代码结构如下：
.├── CMakeLists.txt├── main.cppmain.cpp:
#include &amp;lt;iostream&amp;gt; int main(int argc, char *argv[]) { std::cout &amp;lt;&amp;lt; &amp;#34;Hello Build Type!&amp;#34; &amp;lt;&amp;lt; std::endl; return 0; } CMakeLists.txt下面的内容如下：
cmake_minimum_required(VERSION 3.5)# Set a default build type if none was specified if(NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES) message(&amp;#34;Setting build type to &amp;#39;RelWithDebInfo&amp;#39; as none was specified.&amp;#34;) set(CMAKE_BUILD_TYPE RelWithDebInfo CACHE STRING &amp;#34;Choose the type of build.&amp;#34; FORCE) # Set the possible values of build type for cmake-gui  set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS &amp;#34;Debug&amp;#34; &amp;#34;Release&amp;#34; &amp;#34;MinSizeRel&amp;#34; &amp;#34;RelWithDebInfo&amp;#34;)endif()# Set the project name project (build_type)# Add an executable add_executable(cmake_examples_build_type main.</description>
    </item>
    
    <item>
      <title>All You Need for CMake系列07——Compile Flags</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9707compile-flags/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9707compile-flags/</guid>
      <description>All You Need for CMake系列07——Compile Flags 准备代码 代码结构如下：
.├── CMakeLists.txt├── main.cppmain.cpp:
#include &amp;lt;iostream&amp;gt; int main(int argc, char *argv[]) { std::cout &amp;lt;&amp;lt; &amp;#34;Hello Compile Flags!&amp;#34; &amp;lt;&amp;lt; std::endl; // only print if compile flag set #ifdef EX2  std::cout &amp;lt;&amp;lt; &amp;#34;Hello Compile Flag EX2!&amp;#34; &amp;lt;&amp;lt; std::endl; #endif  #ifdef EX3  std::cout &amp;lt;&amp;lt; &amp;#34;Hello Compile Flag EX3!&amp;#34; &amp;lt;&amp;lt; std::endl; #endif  return 0; } CMakeLists.txt下面的内容如下：
cmake_minimum_required(VERSION 3.5)# Set a default C++ compile flag set (CMAKE_CXX_FLAGS &amp;#34;${CMAKE_CXX_FLAGS} -DEX2&amp;#34; CACHE STRING &amp;#34;Set C++ Compiler Flags&amp;#34; FORCE)# Set the project name project (compile_flags)# Add an executable add_executable(cmake_examples_compile_flags main.</description>
    </item>
    
    <item>
      <title>All You Need for CMake系列08——Third-Party Library.md</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9708third-party-library/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9708third-party-library/</guid>
      <description>All You Need for CMake系列08——Third-Party Library.md 准备代码 代码结构如下：
.├── CMakeLists.txt├── main.cppmain.cpp:
#include &amp;lt;iostream&amp;gt;#include &amp;lt;boost/shared_ptr.hpp&amp;gt;#include &amp;lt;boost/filesystem.hpp&amp;gt; int main(int argc, char *argv[]) { std::cout &amp;lt;&amp;lt; &amp;#34;Hello Third Party Include!&amp;#34; &amp;lt;&amp;lt; std::endl; // use a shared ptr  boost::shared_ptr&amp;lt;int&amp;gt; isp(new int(4)); // trivial use of boost filesystem  boost::filesystem::path path = &amp;#34;/usr/share/cmake/modules&amp;#34;; if(path.is_relative()) { std::cout &amp;lt;&amp;lt; &amp;#34;Path is relative&amp;#34; &amp;lt;&amp;lt; std::endl; } else { std::cout &amp;lt;&amp;lt; &amp;#34;Path is not relative&amp;#34; &amp;lt;&amp;lt; std::endl; } return 0; } CMakeLists.</description>
    </item>
    
    <item>
      <title>All You Need for CMake系列09——Sub-Projects</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9709sub-projects/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9709sub-projects/</guid>
      <description>All You Need for CMake系列09——Sub-Projects 准备代码 代码结构如下：
.├── CMakeLists.txt├── subbinary│ ├── CMakeLists.txt│ └── main.cpp├── sublibrary1│ ├── CMakeLists.txt│ ├── include│ │ └── sublib1│ │ └── sublib1.h│ └── src│ └── sublib1.cpp└── sublibrary2├── CMakeLists.txt└── include└── sublib2└── sublib2.hCMakeLists.txt:
cmake_minimum_required (VERSION 3.5)project(subprojects)# Add sub directories add_subdirectory(sublibrary1)add_subdirectory(sublibrary2)add_subdirectory(subbinary)subbinary/CMakeLists.txt:
project(subbinary)# Create the executable add_executable(${PROJECT_NAME} main.cpp)# Link the static library from subproject1 using it&amp;#39;s alias sub::lib1 # Link the header only library from subproject2 using it&amp;#39;s alias sub::lib2 # This will cause the include directories for that target to be added to this project target_link_libraries(${PROJECT_NAME} sub::lib1 sub::lib2 )subbinary/main.</description>
    </item>
    
    <item>
      <title>All You Need for CMake系列10——Installer</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9710installer/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9710installer/</guid>
      <description>All You Need for CMake系列10——Installer 生成的可执行程序距离发布出去给大众使用，只剩下最后一步，就是打包installer。 CMake中使用CPack来打包RPM，deb，gzip等格式的安装包。本文将以Deb包为例。
准备代码 代码结构如下：
.├── cmake-examples.conf├── CMakeLists.txt├── include│ └── Hello.h└── src├── Hello.cpp└── main.cppcmake-examples.conf：这里创建一个空文件即可
Hello.h:
#ifndef __HELLO_H__ #define __HELLO_H__  class Hello { public: void print(); }; #endif Hello.cpp:
#include &amp;lt;iostream&amp;gt; #include &amp;#34;Hello.h&amp;#34; void Hello::print() { std::cout &amp;lt;&amp;lt; &amp;#34;Hello Install!&amp;#34; &amp;lt;&amp;lt; std::endl; } main.cpp:
#include &amp;#34;Hello.h&amp;#34; int main(int argc, char *argv[]) { Hello hi; hi.print(); return 0; } } CMakeLists.</description>
    </item>
    
    <item>
      <title>All You Need for CMake系列11——Pybind11</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9711pybind11/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-cmake%E7%B3%BB%E5%88%9711pybind11/</guid>
      <description>All You Need for CMake系列11——Pybind11 有时我们需要给c++的底层代码套上一个python的wrapper，此时就需要用pybind11了，当然还有一些别的工具可以做这个事情，这里就不多说了。
安装pybind11 pybind11有两种常用的安装方式，一种是用pip install pybind，一种是git clone https://github.com/pybind/pybind11.git
准备代码 代码结构如下：
.├── CMakeLists.txt└── src└── main.cpp如果是用git clone的方式下载，代码结构如下：
.├── CMakeLists.txt└── src└── main.cpp└── pybind11main.cpp:
#include &amp;lt;pybind11/pybind11.h&amp;gt; int add(int i, int j) { return i + j; } namespace py = pybind11; PYBIND11_MODULE(cmake_example, m) { m.doc() = R&amp;#34;pbdoc( Pybind11 example plugin )pbdoc&amp;#34;; m.def(&amp;#34;add&amp;#34;, &amp;amp;add, R&amp;#34;pbdoc( Add two numbers )pbdoc&amp;#34;); m.def(&amp;#34;substract&amp;#34;, [](int i, int j) { return i - j }, R&amp;#34;pbdoc( Substract two numbers )pbdoc&amp;#34;); } CMakeLists.</description>
    </item>
    
    <item>
      <title>All You Need for Pybind11系列01——编译包到python库</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-pybind11%E7%B3%BB%E5%88%971%E7%BC%96%E8%AF%91%E5%8C%85%E5%88%B0python%E5%BA%93/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/all-you-need-for-pybind11%E7%B3%BB%E5%88%971%E7%BC%96%E8%AF%91%E5%8C%85%E5%88%B0python%E5%BA%93/</guid>
      <description>All You Need for Pybind11系列01——编译包到python库 本系列Pybind11的安装方式默认为pip install pybind11
CMake安装包到python库 详情请见这篇文章，注意这样生成的python库的so文件在build下，而不在当前环境的site-packages下面
g++安装包到python库 考虑到我们搞的是相对大型的系统，这种安装方式对包管理很不友好，因此不在这里多说。如果感兴趣，可以看看pybind11的官方文档。
setuptools安装包到python库 准备代码 代码结构如下：
.├── CMakeLists.txt└── src└── main.cpp└── setup.py└── pyproject.toml就是在CMake安装方式之外要多准备一个setup.py文件。其中CMakeLists.txt和main.cpp中的内容和CMake教程中一致。
# -*- coding: utf-8 -*- import os import sys import subprocess from setuptools import setup, Extension from setuptools.command.build_ext import build_ext # Convert distutils Windows platform specifiers to CMake -A arguments PLAT_TO_CMAKE = { &amp;#34;win32&amp;#34;: &amp;#34;Win32&amp;#34;, &amp;#34;win-amd64&amp;#34;: &amp;#34;x64&amp;#34;, &amp;#34;win-arm32&amp;#34;: &amp;#34;ARM&amp;#34;, &amp;#34;win-arm64&amp;#34;: &amp;#34;ARM64&amp;#34;, } # A CMakeExtension needs a sourcedir instead of a file list.</description>
    </item>
    
    <item>
      <title>手眼标定的福音，Easy HandEye从入门到精通</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/easy_handeye-tutorial/</link>
      <pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/easy_handeye-tutorial/</guid>
      <description>A tutorial on using easy-handeye to calibrate robot arm Easy-handeye can calibrate both eye-in-hand and eye-on-base robot arm.
Pre-requests The following pre-requests are some bugs that I met when I first ran Easy-handeye. I cannot make sure all dependencies are listed. Most bugs or errors come from the shortage of ros packages, please install them based on error logs.
1. Make sure ROS and Moveit is successfully installed. ROS should be installed in desktop-full version.</description>
    </item>
    
    <item>
      <title>Articulation入库系列3——URDF格式的articulation模型转fbx格式</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/articulation%E5%85%A5%E5%BA%93%E7%B3%BB%E5%88%973urdf%E6%A0%BC%E5%BC%8F%E6%A8%A1%E5%9E%8B%E8%BD%ACfbx%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/articulation%E5%85%A5%E5%BA%93%E7%B3%BB%E5%88%973urdf%E6%A0%BC%E5%BC%8F%E6%A8%A1%E5%9E%8B%E8%BD%ACfbx%E6%A8%A1%E5%9E%8B/</guid>
      <description>URDF格式的articulation模型转fbx格式 所需软件   Blender （这里使用Blender 2.83版本）
  Unity 2020.1.0f1c1（Unity用于fbx文件验证，其他版本应该也可以）
  评注（Wenqiang） 我们目前对joint的标注已基本unity化，unity导入articulation时，只需要part的hierarchy，其具体的转轴可以在unity里面调，而且比较方便（thanks to ArticulationBody这个feature），所以下述步骤实际上只需要1-2-3-11-12即可，在第二步中打开urdf，根据urdf数值调整每个part的位置和朝向。
在unity中如何标注joint，请参考这篇文章。
详细步骤   打开Blender，删除默认的cube, camera和light三个部件，导入物体obj模型，如果是articulation物体，需分别导入各个part的obj
  （optional）由于本教程示例的urdf由unity的ROS#插件制作而来，所以其坐标系会和blender默认有所不同，导入时初始位置会有X旋转90度的情况，需手动修正
  打开纹理渲染，确认物体纹理导入正确
  为articulation物体建立运动结构，如图所示，把base_link作为link1的父节点
  之后为可运动part建立旋转（或平移）的运动模式，首先打开urdf文件，获取link1运动的类型、旋转中心、旋转方向和旋转limit，即type, origin xyz, axis xyz, limit
  在blender中选择左侧游标，根据旋转中心和转轴方向为游标设置位置和方向参数，这里需要注意，同上文所说，我们制作的urdf在坐标系上略有不同，所以这里三个值输入顺序需要有一个变化，具体为：旋转中心(x,y,z) -&amp;gt; (y,z,x) 旋转方向 (r,p,y) -&amp;gt; (p,y,r)(注：该变化在不同source的urdf中并不完全一致，还是以手调为准)
输入后可以看出，3D游标位置处于link1旋转的中心点
  验证旋转中心及位置的正确性，选择左侧旋转，旋转位置选择3D游标，略微转动物体，可以看出link1旋转模式符合预期
  添加物体旋转约束，选择link1，在右下角菜单栏选择“物体约束属性”-“添加物体约束”-“限定旋转”，这里我们选择Y限值（刚刚旋转演示中的绿色旋转方向）为urdf中的两个limit（角度数值需要转换）
  再次旋转物体，可以发现，当旋转超过限值后，将出现part脱离现象
  刚刚只是设置游标验证运动方式，现在要将旋转中心和方向记录在link1中。选中link1，鼠标移至游标位置右键，选择设置原点，原点-&amp;gt;3D游标，即可将3D游标位置设置为物体旋转点，如图所示，右上角位置中已经变成了3D游标位置
   将纹理写入模型中，在右下角选择纹理，将纹理打包按钮点亮，保证纹理被内嵌到模型里
  导出fbx，点击文件-导出-fbx，路径模型选择“复制”，并将右侧内嵌纹理点亮，导出为box1.fbx模型文件
  （optional）在Unity里验证fbx，打开unity工程，导入box1.</description>
    </item>
    
    <item>
      <title>MoveIt ROS切除术1——核心planner</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/moveit-ros%E5%88%87%E9%99%A4%E6%9C%AF1%E6%A0%B8%E5%BF%83planner/</link>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/moveit-ros%E5%88%87%E9%99%A4%E6%9C%AF1%E6%A0%B8%E5%BF%83planner/</guid>
      <description>MoveIt ROS切除术1——核心planner 目前的RobotFlow-rFUniverse战术体系中不需要ROS，或者说我们在尽可能地减少ROS的影响，在这种情况下，我们要尽可能把原来ROS中的一些核心部件去ROS化。
如果去不了的，就考虑怎么在不影响RobotFlow体系的情况下共存。
首先下刀的，就是ROS最重要的库（可能没有）之一MoveIt。根据MoveIt Concepts，整个MoveIt框架里有大量的外层封装与ROS体系适配。因此我们要对MoveIt做切除，一个比较简单的策略是先把里面的规划核心库搬出来。然后参考MoveIt对ROS的封装，自己写一套封装。
截至2021年1月，MoveIt引入了5种外部规划器插件，其中最重要的是OMPL，别的有CHOMP，SBPL，trajopt，pilz_industrial_motion_planner。
主要的规划库 —— OMPL OMPL全称是The Open Motion Planning Library，是一个包含了大量sampling-based算法的运动规划库，典型的如RRT，PRM及其变种在里面都有。 OMPL也有大量的实践是不依赖于ROS的，比如有现成的流程和V-REP，OpenRAVE，MORSE等整合。
OMPL目标是打造一个standalone的规划库，自己不带任何前端和collision detection，但官方的偏好是FCL和PQP。考虑到MoveIt也是用的FCL，那么这一套pipeline就保留下来。
次要的规划库 —— SBPL SBPL的全称是Search-Based Planning Library，顾名思义，里面有大量search-based的算法，类似A*这样。这个库本身也可以独立于ROS编译。
特有的规划算法 —— CHOMP CHOMP的论文很容易找到，就不说了，但是它的代码比较难找，因为to the best of my knowledge，论文作者并没有其官方实现，只有在MoveIt里有一个和ROS集成得很紧密的CHOMP实现。因此要把CHOMP拉出来，需要进一步地剥离ROS的痕迹。 这个算法自带碰撞检测，能规避掉障碍物，不过貌似调参可能有坑，可以看看这个issue。
新加的规划算法 —— trajopt trajopt也是一个基于论文出来的规划算法，论文作者放出了代码，可以独立编译。据说速度比OMPL和CHOMP快。
面向工业场景的规划库 —— pilz industrial motion planner 这个motion planner是最近加入MoveIt的规划器，不过从它的文档来看，更多的像是一个轨迹生成器。
围绕planner的接口  仿真环境分为visual environment，以及collision environment。送入planner的是collision environment，这也就要求仿真器能把所有collision的状态都返回回来。 仿真器的规划需要一个规划组，这个规划组的定义可以参考moveit_config，或者直接用（毕竟那个assistent还是比较好用的，而且assistent有了之后也可以暂时不考虑kinematics solver） 有了collision state，机器人的规划组，我们就能使用规划算法了。  </description>
    </item>
    
    <item>
      <title>RobotFlow工程track半年度总结（2020.7~2021.1）</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/robotflow%E5%B7%A5%E7%A8%8Btrack%E5%8D%8A%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%932020.7~2021.1/</link>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/robotflow%E5%B7%A5%E7%A8%8Btrack%E5%8D%8A%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%932020.7~2021.1/</guid>
      <description>RobotFlow工程track半年度总结（2020.7~2021.1） RobotFlow项目从7月份正式启动到现在也有半年了，中间经历了招工程师，CVPR投稿等拖延进度的事情，还是完成了一些事情。 在大方向不变的情况下，现在的robotflow项目已经和最开始的想法有了不少结构性的调整。现对该方向做一个总结，并对未来做一个简单的规划。
多级结构 rflib -&amp;gt; rflearner -&amp;gt; perception -&amp;gt; rfplanner -&amp;gt; task env controller
以上用rf开头的库，之后都会考虑往独立的库发展。特别是rflib。
 rflib：  放各种需编译的代码，其代码编译好后通过pybind被python调用。 放逻辑上偏底层的代码   rflearner：所有learning相关的代码，算法逻辑层 perception：  detector：含目标检测和实例分割 pose estimator：6DoF估计算法 human analyzer：人体/手检测，重建算法；intent modeling相关算法 action preprocessor：视觉驱动的robot learning算法的前端（这一部分的网络末尾通常是没有loss的，是通过RL的部分来优化的），这部分视具体任务会拆分，不会用这个名字总包所有的模型。   rfplanner  TAMP规划器Rogic MP规划器RFMove   task  分层结构，从单primitive到复合任务，都统归到task里 单primitive时，地位和perception相同 复合任务时，单primitive和perception算法可能都是其子任务   env  提供真实场景的可视化，模拟规划 提供仿真场景的可视化，模拟规划，交互   controller：  提供各种硬件控制器的上层封装：位置控制，速度控制，力控    举个例子：
 视觉的人视角：pytorch提供基本的conv2d实现；rflib提供注入roialign这样的ops的实现；rflearner提供resnet的实现；detector描述（config）怎么搭一个yolov3的pipeline Robot的人视角：rflib提供各种硬件接口，c++功能代码；env，controller，rfplanner等提供对应功能的上层封装；task描述一个完整的机器人任务（可以无视觉） Robot Learning的人视角：pytorch功能同上；rflib功能同上；rflearner提供ppo等算法逻辑；perception部分描述（config）robot learning的视觉前端，task部分描述（config）各机器人技能（primitive），并描述（config）视觉前端和各机器人技能该如何串联。模型保存的方式有两种，视觉前端和机器人操作后端分别保存/统一保持。  去ROS化进程 去ROS化是一直以来的大方针，ROS生态中有很多重要的软件都是基于ROS的通信机制来写的，而且往往是独占。那么在去ROS化的过程中，很重要的一步就是要对这些功能进行替换，这中间会涉及到大量的代码重写和重构。</description>
    </item>
    
    <item>
      <title>unity踩坑指南（持续更新）</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/unity%E7%9A%84%E5%9D%91%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/</link>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/unity%E7%9A%84%E5%9D%91%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/</guid>
      <description>Unity踩坑指南  universal render pipeline  URP和部分自定义shader有冲突，目前原因未名 URP和flex插件有冲突，会导致其显示不正常 igibson内置的纹理目前需要在URP下才能成功渲染，原因未名 URP和3D模式下的step时长有区别   unity中不含有运动规划器，因此需要另外写，关于这部分请参看这篇文章  另一个solution是官方的Unity Robotics Hub，这个项目野心很大，基本来说是想让unity接入ROS生态，目前刚开始，bug还比较多。而且Unity当前自带的PhysX的版本不是非常给力（参见下面PhysX的条目）。   Flex插件  Flex插件目前在ubuntu版本的unity下有bug，具体原因未知，在windows环境下正常   PhysX  这个不能怪unity，但是physx其实早有5.0版本，而且有比较完善的粒子系统（可以替代Flex），但是Nvidia出于某种目的没有开放（估计是先在Issac Sim里爽爽）。    </description>
    </item>
    
    <item>
      <title>C Sharp玩unity系列4——透明材质、折射与反射</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/c-sharp%E7%8E%A9unity%E7%B3%BB%E5%88%974%E9%80%8F%E6%98%8E%E6%9D%90%E8%B4%A8%E6%8A%98%E5%B0%84%E4%B8%8E%E5%8F%8D%E5%B0%84/</link>
      <pubDate>Thu, 24 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/c-sharp%E7%8E%A9unity%E7%B3%BB%E5%88%974%E9%80%8F%E6%98%8E%E6%9D%90%E8%B4%A8%E6%8A%98%E5%B0%84%E4%B8%8E%E5%8F%8D%E5%B0%84/</guid>
      <description>C Sharp玩unity系列4——透明材质、折射与反射 Cubemap 一个免费的Cubemap资源网站：HDRI Haven。
Material与Shader Shader在本话题中的地位非常重要，在这里先贴上知乎《零基础入门Unity Shader》系列文章。
 零基础入门Unity Shader（一） 零基础入门Unity Shader（二） 零基础入门Unity Shader（三） 零基础入门Unity Shader（四） 零基础入门Unity Shader（五） 零基础入门Unity Shader（六） 零基础入门Unity Shader（七） 零基础入门Unity Shader（八） 零基础入门Unity Shader（九） 零基础入门Unity Shader（十）  Material是材质球，Shader是着色器。Material和Shader之间的关系是，Material使用Shader：一个Material只能使用一个Shader，而一个Shader可以被多个Material使用。需要注意的是，每一个Material使用的着色器都是一个Shader实例。举个例子，一个Shader文件叫做MyCustomShader.shader，其中包含一个变量Smoothness，默认值为0.5，而Material A和Material B都要使用MyCustomShader.shader。这时，我们可以在Material A和Material B中任意改动Smoothnesss的值，而A和B互不影响。
因此，Shader文件就是我们要编写的着色器文件，它定义了一个材质在camera中看起来是什么样子的。Shader文件可以看作是一个小小的算法，用于计算物体mesh的每一个vertex和face渲染到2D图像上的像素值。这个话题继续展开下去就是CG领域的内容了，可能需要学很多CG的知识才能研究的很透彻。
但幸运的是，Unity的HDRP（High Definition Render Pipeline）和URP（Universal Render Pipeline）模板创建的项目可以使用Shader Graph这个图形化界面来编写Shader。这种情况下，各个组件变成了输入和输出，只需要按照规则将数据流穿起来，就可以自动生成Shader文件。
 在网上的tutorial中还有人介绍到LWRP（Light Weight Render Pipeline）模板也可以使用Shader Graph，但是我的版本中没有找到这个模板，因此就略过了。
 此外，HDRP模板中的材质本身就可以增设折射属性，这使得我们不用借助Shader去搞伪折射，而直接调参即可。所以我们接下来分两个部分，一个部分是使用Shader Graph工具写一个实现折射+反射+菲涅尔效应（Fresnel Effect）的shadergraph文件；另一部分是直接使用UDRP中的Lit Material，并在此基础上调参实现反射和折射效果。
Shader Graph in URP 首先创建一个新项目，模板选择Universal Rendering Pipeline。
通过摄像机拍摄纹理进行折射 参考视频：here
这个折射Shader是从相机拍摄的图片出发（也就是观察者的视角），通过Unity内置函数refract将图片按照给定的View和Normal以及IOR（折射率）进行折射计算，并把这个结果进行一系列的后处理，最终放在物体上进行渲染。
这个方法显然是一种比较假的折射方式，劣势在于它只能渲染出摄像机看到的画面，如果摄像机看不到，它也就没法折射出来。因此可以看到，当摄像头视角离折射物体较近时，边缘部分会出现条纹效果。如果像视频中一样使用Floor和Substract模块，那么将会出现“万花筒”效果。
但是，这种方法的优势在于，它的计算开销较小，同时在场景中可以更加真实地渲染多个物体，而且不同物体之间也可以相互渲染出来。渲染效果更加真实，实时性也更强。
通过Reflection Probe进行折射 参考视频：here
借助Reflection Probe反射出来的画面进行折射的方式可以更加真实地做出折射的效果。因为这里的折射源不仅仅是摄像机所能拍摄到的范围，而是真实的整个范围。但是相应的也就会出现一些问题，比如</description>
    </item>
    
    <item>
      <title>C Sharp玩unity系列3——ArticulationBody</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/c-sharp%E7%8E%A9unity%E7%B3%BB%E5%88%973articulationbody/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/c-sharp%E7%8E%A9unity%E7%B3%BB%E5%88%973articulationbody/</guid>
      <description>C Sharp玩unity系列3——ArticulationBody 从FXB导入unity Unity官方支持的Hierarchy结构的数据类型是FBX，尽管obj文件+material也可以正常导入Unity，但是因为obj文件本身并不支持层级结构，因此最多就是两层，对于机械臂这种Hierarchy结构的物体来说并不友好。因此我们从FBX类型文件出发，使用代码将其导入unity并生成prefab。具体代码和导入obj文件几乎相同，如下。
string meshName = &amp;#34;demo.fbx&amp;#34;; string prefabName = &amp;#34;demo.prefab&amp;#34;; GameObject gameObject; GameObject go = AssetDatabase.LoadAssetAtPath(meshName, typeof(UnityEngine.Object)) as GameObject; if (go != null) { gameObject = Instantiate(go); PrefabUtility.SaveAsPrefabAsset(gameObject, prefabName); AssetDatabase.Refresh(); Destroy(gameObject); } 有了Prefab之后，就可以直接把prefab导入scene中，接下来就可以真正搞起来了。
ArticulationBody 从Unity2020.10b1以来，Unity开始支持ArticulationBody这个属性。ArticulationBody的物理性质可以认为“继承”自刚体（在代码层面上不是继承关系，这里是一个语义上的“继承”），同时又对不同Joint之间的关系和相对位置进行了约束。
如上图所示，一个逻辑上树形结构的Articulation物体，不同Joint之间的关系是层层递进的，这和ROS中的TF是一脉相承的逻辑关系。当一个part运动时，这个part的所有孩子都会跟随着这个part一起运动。
在使用ArticulationBody时，树形结构中的每一个部分都要add ArticulationBody这个component（这里注意，Unity中的父子关系并不是继承，孩子并不能继承父亲的属性，例如Rigidbody、MeshCollider、ArticulationBody等，父子关系只表现在transform上）。
如果是根节点的part，Inspector窗口中ArticulationBody的属性值如下图。Unity会自动识别该part是否为ArticulationBody的根。如果加了ArticulationBody的part不是从根节点开始的，那么Unity会自动将最靠近根节点的part作为根。例如，上图中，我们只把Shoulder及其所有孩子和后代添加ArticulationBody属性，则Shoulder会被认为是根。
对于其他的part，Inspector窗口的ArticulationBody属性值如下图。
这里最关键的是选项就是Anchor和Articulation Joint Type。由于ArticulationBody是今年新加入的类，官方文档中还没有详细解释，网上的博客也几乎没有，因此我在这里只结合我在使用时试验出的结果以及推测，对上述两个名词进行一定解释，如果后面发现有错误，会随时修改。
Anchor Anchor顾名思义，就是两个part之间相连接的点。Anchor在ArticulationBody中有两部分，一部分是Parent Anchor，还有一部分是这个part本身的Anchor（下直接称Anchor）。一般情况下，我们会勾选Compute Parent Anchor，这时只能调整Anchor，我推测此时的Parent Anchor和Anchor是重合的。当然，也可以不勾选Compute Parent Anchor，手动调整Parent Anchor的position和rotation。但是，我实际尝试发现，即便Parent Anchor飘到一个跟物体毫不相干的位置，也并不会影响正常的运动。
对于Anchor，它的position和rotation是相对于该part的原点而言的。一般而言，一个part的原点就是该part与其父亲part之间相连的点，因此position是(0,0,0)，但是Rotation相对更重要，这关系到一个joint的旋转自由度，详见Articulation Joint Type。
Articulation Joint Type Articulation Joint Type一共有四种：
 FixedJoint：固定关节，0自由度 PrismaticJoint：移动关节，1自由度 RevoluteJoint：旋转关节，1自由度 SphericalJoint：球形轴，3自由度  这里需要强调的是，对于PrismaticJoint，可以自己指定自由度的一个轴；对于RevoluteJoint，需要调整parent anchor，本part只能绕parent anchor的X轴方向旋转。</description>
    </item>
    
    <item>
      <title>C Sharp玩unity系列2——刚体</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/c-sharp%E7%8E%A9unity%E7%B3%BB%E5%88%972%E5%88%9A%E4%BD%93/</link>
      <pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/c-sharp%E7%8E%A9unity%E7%B3%BB%E5%88%972%E5%88%9A%E4%BD%93/</guid>
      <description>C Sharp玩unity系列2——刚体 项目源码 本项目的源码在文件夹Rigidbody_tutorial中，访问请找Haoyuan。
Prefab（预制件）的封装 在Unity中，Prefab是一个被经常使用的类型。一个外部资源（比如obj、fbx、dae文件）往往都要先被封装成Prefab（.prefab文件），然后才能load到Unity的Scene中。这一期教程中暂时还是使用Unity Editor，也就是GUI的方式定制Prefab。
我们以OBJ文件为例。首先要把想要使用的obj文件复制到Assets文件夹下，然后把它拖到Scene中，把Scene列表中的该对象拖回Assets列表里，在弹出的对话框中选择Original Prefab，这时Assets中会自动生成.prefab文件，同时Scene列表中的物体也会自动变为Prefab类型。区分一个物体是不是prefab很简单：从图标上面看，普通的GameObject是一个空心的立方体，而Prefab是蓝色实心的立方体。
Prefab定制好之后，我们可以预先对Prefab进行component的赋予，例如增加碰撞检测、增加刚体、柔体属性等等。我们建议使用以下方法对prefab进行设置。
 在Unity Editor界面的Project窗口中，双击刚才生成好的prefab文件，即可进入Prefab编辑模式。注意，这一模式下你对于prefab的任何修改都是会直接保存到prefab本身的。    左侧的Hierarchy窗口可以看到本prefab的父子结构。我们接下来既可以对prefab本身继续修改，也可以对它的孩子（也就是我们的obj文件所对应的GameObject）进行修改，具体把属性加到谁上面更好，就是task-specific的了。
  想要添加属性，就在inspector窗口的最下面的一个Add Component按钮即可操作。本期教程中只需加入刚体属性和碰撞检测。需要注意的是，碰撞检测如果选用mesh collider，一定要将convex属性勾选为true，这样才可以进行正常的碰撞检测。属性添加完毕后如图所示。（我加在了孩子上）
  运动 封装好了prefab文件后，接下来的部分我们都可以使用代码的方式来获取和控制。对于刚体来说，我们一般初始化时给它生成到一个位置上，然后用力去控制它的运动。首先将prefab拖到scene中，随便放在一个位置就可以，因为我们后续还会用代码对它的位置进行调整。控制的script脚本Move.cs如下
using UnityEngine; public class Move : MonoBehaviour { Rigidbody m_Rigidbody; public float m_Thrust = 10f; void Start() { m_Rigidbody = GetComponentInChildren&amp;lt;Rigidbody&amp;gt;(); // m_Rigidbody = GetComponent&amp;lt;Rigidbody&amp;gt;();  m_Rigidbody.transform.position = new Vector3(0, 0, 0); m_Rigidbody.mass = 10; m_Rigidbody.useGravity = false; } void FixedUpdate() { if (Input.GetKey(&amp;#34;w&amp;#34;)) { m_Rigidbody.</description>
    </item>
    
    <item>
      <title>C Sharp玩unity系列1——导入或创建模型</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/c-sharp%E7%8E%A9unity%E7%B3%BB%E5%88%971%E5%AF%BC%E5%85%A5%E6%88%96%E5%88%9B%E5%BB%BA%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/c-sharp%E7%8E%A9unity%E7%B3%BB%E5%88%971%E5%AF%BC%E5%85%A5%E6%88%96%E5%88%9B%E5%BB%BA%E6%A8%A1%E5%9E%8B/</guid>
      <description>C Sharp玩unity系列1——导入或创建模型  unity版本2020.1，在这个版本中unity引入了articulation（抱PhysX的大腿），使得建模articulated的物体比以往容易了很多。因此，我们的教程需要建立在2020.1以后的版本上。在不需要这个功能的时候，其他基础功能用别的版本应该也可以实现。
 写在前面 仿真在我们的科研中占据了越来越重要的地位，一个很简单的逻辑就是，以后组里做机器人的同学越来越多，但是组里的机器人并没有那么多，那么必然需要一个好用的仿真环境来先验证想法。
目前面向机器人的几个仿真器包括gazebo，v-rep，mujoco，pybullet都比较阉割，对高保真渲染，高级建模（柔性，撕裂，流体等）支持都不是特别到位。而通用的仿真器，包括unity和unreal engine，学起来成本又很大。其中unity相对容易上手，通用性比较强，原生自带physX，和steamVR，mujoco之间都有混编的接口，虽然渲染比不过unreal，但也够用了。所以虽然需要额外学一个C#，但我们还是选择从unity开始上手。
和Chrono这样的纯学术用物理引擎不同，unity是一个集成了前端后端各个环节的大框架。因此在创建unity相关的工程的时候通常是需要前端editor和C# scripting并用的。我们会在教程中尽量让能用code搞定的事情都用code搞定。
本教程主要参考自官方手册 Version 2019.4和catlikecoding的Unity C#教程，网上的tutorial大多面向游戏开发或者CG，对我们这种CV-Robotics oriented的researcher极度不友好。因此希望本系列教程能bridge这个gap。
本教程配套的脚本请见rf_unity_tutorial@github，目前还是private，有需要可以找Haoyuan要访问权限。文章中只给出关键性的代码，完整的请参考配套脚本。
加载Mesh 对于我们来说，第一个需要处理的问题就是如何把模型载入unity场景。
Unity目前官方支持的3D格式是FBX。我们常用的Obj也行，但如果要通过Obj的方式articulation的物体就不行了。所以我们还是老老实实用FBX格式，避免出现一些不必要的问题。 此外ROS#和URDF importer能直接读取URDF文件，不过各自都有各自的问题。 一个对物体和机器人都比较适中的方案是把URDF转成FBX，当然FBX承载不完URDF的所有信息，但是对于unity来说还是够用了。
Obj转FBX 网上有很多在线转的方案，不过通常纹理是没有的。
软件上MeshLab是不支持转换了（诡异的是它可以打开），不过Blender可以，也是带纹理的。官方也推荐用Maya或者3ds Max（最近好像版权到期了，2021年1月），这俩交大买了，不过Blender基本够用了，轻量，支持python脚本，还完全开源完全免费，各种插件也多，所以还是推荐用blender。
 FBX是Autodesk推出的文件格式，Blender的FBX是用的自己写的reader/writer，所以如果实践中发现了什么奇怪的事情，还是用回官方SDK。官方SDK是免费但是闭源的，所以Blender的实现其实基本靠猜（但一般情况还是可以了）。
 不过Blender的使用也是一个大坑，因为功能很多，我们会在这个教程里穿插着讲，但不会系统地讲。关于如何用python控制Blender，可以参考官方文档。
这里只针对格式转换的部分，脚本如下：
import bpy # remove the default cube if &amp;#34;Cube&amp;#34; in bpy.data.meshes: mesh = bpy.data.meshes[&amp;#34;Cube&amp;#34;] print(&amp;#34;removing mesh&amp;#34;, mesh) bpy.data.meshes.remove(mesh) bpy.ops.import_scene.obj(filepath=&amp;#34;path/to/model.obj&amp;#34;) bpy.ops.export_scene.fbx(filepath=&amp;#34;path/to/model.fbx&amp;#34;) 关于支持Articulation的问题 从格式上来说，其实刚体，柔性物体，撕裂效果等是很容易的，一个unified的模型就可以，不过表示articulated的物体反而有点难，因为需要模型能支持hierarchy结构，并且能individually地控制每一个part。因为obj只支持一个级别的hierarchy（o-&amp;gt;g），因此多层次的连杆结构（比如机械臂）是没法直接通过obj支持的。不过dae和fbx是支持多层hierarchy的。
那么我们要如何准备articulation的数据呢？Robotics界通用的做法是用URDF，所以我们要做的事情就是把urdf转换成fbx。因为我们前面说了FBX并没有开源，所以URDF到FBX的converter就很难写。一种方案是借助ROS里的包collada_urdf把urdf文件转成dae文件，再把dae文件转成fbx。dae文件的读取在blender里是bpy.ops.wm.collada_import。嗯，这种inconsistency一看就是老开源了~不过这个ROS包质量很差，而且已经没人维护了。
另一种方案就是一边解析URDF，一边通过blender把各个part的模型读进blender，然后完成hierarchy的组装，再export出来。这个过程的自动化还在进行中，目前的流程请参考这篇文章。
C#加载FBX模型 GameObject obj = (GameObject) Object.Instantiate(Resources.Load(&amp;#34;PrefabName&amp;#34;)) Unity里面Prefab是一个很常用的概念，这个词原意是预先建造的房屋，换句话说就是提前准备好的资源。在Unity中，一个.fbx文件（或者美工的.psd,.sai文件）都会先被封装成Prefab文件，此时它才可以在Editor中随便拖拽。关于Prefab的使用可以到网上去搜一下，它的基本的几个性质包括：
 在动画，交互中，场景中的GameObject可能会发生改变（比如被切开，柔性变换），但prefab是不变的 上面这一条的好处是，我可以随便复用prefab，不用每创建一个GameObject就复制一次 自然的，它就可以支持在仿真进行的过程中动态实时地创建物体。而不用把所有的物体都事先拖到场景中，隐藏起来，等需要的时候再显示。  Instantiate函数内在地封装了AddComponent和AddComponent，除非我们在玩Procedural Modeling，没有什么必要用这种方式处理mesh。我们下面给出一个创建简单几何Primitive，并用Procedural Modeling方式得到更复杂的模型的例子。</description>
    </item>
    
    <item>
      <title>Articulation入库系列2——CAD模型（part-level）转换为URDF格式, 2nd edition</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/articulation%E5%85%A5%E5%BA%93%E7%B3%BB%E5%88%972cad%E6%A8%A1%E5%9E%8Bpart-level%E8%BD%AC%E6%8D%A2%E4%B8%BAurdf%E6%A0%BC%E5%BC%8F_v2/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/articulation%E5%85%A5%E5%BA%93%E7%B3%BB%E5%88%972cad%E6%A8%A1%E5%9E%8Bpart-level%E8%BD%AC%E6%8D%A2%E4%B8%BAurdf%E6%A0%BC%E5%BC%8F_v2/</guid>
      <description>CAD模型(part-level)转换为URDF格式 所需软件   Unity 2020.1.0f1c1（也可以使用低一点的Unity版本，但是流程未经验证，推荐使用该版本）
  下载链接 https://unity.cn/releases 建议从Unity Hub下载安装。
  Unity入门视频教程 https://www.bilibili.com/video/BV1B7411L74W 只需要看[P1, P3, P13]，了解最基本的编辑器操作即可。
  使用ROS #插件创建和导出URDF视频教程（作为参考）https://youtu.be/07q2mGxD2j8
    Blender 2.80 （建议使用该版本）
 下载链接 https://download.blender.org/release/Blender2.80/    详细步骤 准备工作   创建新项目（不同的物体可以共用一个项目，只要创建一次项目就可以）。（注意Unity可能每天都要手动激活一次）选择3D项目，如下图所示：
  将ROS#插件添加到Unity的资源中。
在Unity的Package Manager中找到ROS#插件，选择Import（若第一次使用需点击Download）。
在弹出的窗口中继续点击Import，导入所有代码。
  转换面片模型(.obj -&amp;gt; .fbx)   打开Blender，鼠标左键选择默认的Collection，鼠标右键选择Delete Hierarchy，把系统默认自带的物体都删除。
  在File菜单中选择Import-&amp;gt;Wavefront(.obj)，并选择想要导入的文件。
  导入之后可以使用鼠标滚轮放缩物体，此时我们可以看到物体还没有纹理，按下Z选择Rendered模式显示纹理。在右侧的材质选项中还可以调节具体参数（可选）。如下图所示：
  更改物体名字和material名字，如下图所示：
  在右侧选中该物体，选择File-&amp;gt;Export-&amp;gt;FBX(.fbx)
建议只选中左下角的Mesh，选择FBX Units Scale，同时选择Selected Objects，然后点击右上角的Export FBX。</description>
    </item>
    
    <item>
      <title>当我们在谈论Motion Primitive的时候究竟在谈论什么</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/%E5%BD%93%E6%88%91%E4%BB%AC%E5%9C%A8%E8%B0%88%E8%AE%BAmotion-primitive%E7%9A%84%E6%97%B6%E5%80%99%E7%A9%B6%E7%AB%9F%E5%9C%A8%E8%B0%88%E8%AE%BA%E4%BB%80%E4%B9%88/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/%E5%BD%93%E6%88%91%E4%BB%AC%E5%9C%A8%E8%B0%88%E8%AE%BAmotion-primitive%E7%9A%84%E6%97%B6%E5%80%99%E7%A9%B6%E7%AB%9F%E5%9C%A8%E8%B0%88%E8%AE%BA%E4%BB%80%E4%B9%88/</guid>
      <description>当我们在谈论Motion Primitive的时候究竟在谈论什么 当Author们没有claim自己在做Skill的时候他们在做什么？ 他们在做把skill当成一个个的具体的topic来做，比如grasp，throw，slide，pour water啥的。 以Grasp为例，有关它的可迁移性，有这么几个层次：
  基于共性结构的抓取：不一定要求物体是同一类，可以是（较）deformable的物体，但还没见到能从rigid到highly flexible的物体。
 当共性结构是（相对dense的）几何特征：就是当物体的外形比较相似的时候，那么抓法也应该比较相似。这时给几个example demonstration，它就能抓很多这类的物体。这样的工作很多了。 当共性结构是稀疏的点：那么相似性主要看基于几个关键点连成的拓扑。如下图 此时迁移性取决于物体的结构，首先只能在同一套结构里迁移，一套结构当然不可能处理所有物体的。    基于语义的抓取：
 最coarse的语义是类别，当然这种情况下迁移能力是很弱的，而且就要求必须要先识别出物体来 稍微好一点的是有语义的part segmentation  总的说来，语义和抓取之间没有直接的联系，不过这是抓取这个task的问题，因为抓取本来也没必要有语义。在manipulation中，语义所蕴含（或者来自知识库attach）的功能性还是值得关注的。
  基于抓型相似性的抓取：这个如下图， 因为人手和gripper之间的巨大差异，所以设计一种手持二指gripper，上面装载各种传感器。这样可以减轻human demonstration和机器人grasp之间的gap。从而可以直接处理grasp时的策略（而不是像以前要经过一些间接的表示，比如来自物体的，或者需要把五指的人手投影到二指）。
  当然，还有单做其他的skill的，这里就不一一例举了。为什么有些skill能单独成为一个topic/task，有的只是在文章里顺带做做？ 比如stacking，push，pick-and-place这些通常都是顺带跟着grasping做做。像insert，pour water这些偶尔还会单独成篇。我个人认为，核心原因是背后的动力学不一样，比如insert，最关键的是靠近hole的时候的试探过程。
当Author们claim自己在做Skill的时候他们在做什么？ 当然，也有把skill整个一起看的。这时候他们的论文标题就会带上skill这样的字眼。以一份CMU RI的老师，18年做的一个slide为例，可以看看这一派人对问题的思考。
基本目标：学可复用的Skill  Skill要能反映manipulation task的结构：  把task分解成segments skill负责在segments之间转移 需要high-level的policy来组织这些skills来完成task     对于一个简单的grasp task来说： 我们可以把它分成3个segments，在ppt里叫mode。
 Mode 1：准备阶段 Mode 2：Contact Mode 3：物体离开平面   因此，引入mode这个概念后，就可以定义motor primitive，上面那张图的范式就变成：
 把Demonstration分解成Modes 学motion primitive用于mode之间的转移 优化各个primitive的goal state：  Use learned forward model as simulator Use mode transition distribution to define reward    具体来说，可以用这样的技术来解：</description>
    </item>
    
    <item>
      <title>Articulation入库系列1——从3D扫描数据生成CAD模型（part-level）, 5th edition</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/articulation%E5%85%A5%E5%BA%93%E7%B3%BB%E5%88%9713d%E6%89%AB%E6%8F%8F%E6%95%B0%E6%8D%AE%E8%BD%AC%E6%8D%A2%E4%B8%BA-cad%E6%A8%A1%E5%9E%8Bpart-level_v5/</link>
      <pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/articulation%E5%85%A5%E5%BA%93%E7%B3%BB%E5%88%9713d%E6%89%AB%E6%8F%8F%E6%95%B0%E6%8D%AE%E8%BD%AC%E6%8D%A2%E4%B8%BA-cad%E6%A8%A1%E5%9E%8Bpart-level_v5/</guid>
      <description>从3D扫描数据生成CAD模型（part-level） 所需软件  ExScan Pro 3X 2020（3D扫描仪自带的软件） Geomagic Deisign X 2019（逆向工程软件，可以用于把3D点云变为CAD模型）基本使用方法可见教程（只需要看前面6节视频）  操作步骤概要   标定手持扫描仪相机。   使用手持扫描仪进行扫描。   使用ExScan软件进行后处理（补洞、拼接等），并封装模型，生成点云模型(.asc)和面片模型(.obj)。   使用Design X软件对物体的整体面片模型(.obj)和点云模型(.asc)对齐坐标轴，具体操作步骤如下：   更改默认测量单位(mm-&amp;gt;m)。
  （可选）对面片模型进行优化，进行加强形状、填孔等。
  进行自动领域分割，根据情况微调（合并、重分块，调整几何类型等）。
  创建参考平面、面片草图、草图等，为接下来的手动对齐提供参考。
  手动对齐（同时对齐点云和面片），确定坐标轴的位置和方向。
  导出对齐后的整体面片模型(.obj)和点云模型(.asc)。
    使用Design X软件导出Joint（旋转轴、平移轴），具体操作步骤如下：  创建参考平面、面片草图、草图等，为画出Joint提供参考。 利用直线工具画出各个Joint，可以根据需要手动微调。 导出Joint对应的直线信息（.txt）。    使用Design X软件分割物体，具体操作步骤如下：  把点云分割成多个part。 利用每个part的点云自动生成面片，并把之前的整体面片模型的纹理复制上去，得到每个part的面片模型。 修改每个part的面片模型(.obj)的材质，使每个part的材质都是一样的。 导出每个part的面片模型(.obj)和点云模型(.asc)。    （？？？暂时可以省略）使用Design X软件对每个part的面片模型(.obj)和点云模型(.asc)对齐坐标轴，具体操作步骤如下：   为每个part创建新工程，导入步骤6中生成的面片模型和点云模型。</description>
    </item>
    
    <item>
      <title>RobotFlow工程track一期</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/robotflow%E5%B7%A5%E7%A8%8Btrack%E4%B8%80%E6%9C%9F/</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/robotflow%E5%B7%A5%E7%A8%8Btrack%E4%B8%80%E6%9C%9F/</guid>
      <description>RobotFlow工程track RobotFlow是封装在机器人通信系统之上的应用平台。它通过封装通用（ROS）或专用操作系统（FCI for Franka），让上层应用不用关心其输出的数据是怎么被其他模块使用，也不用担心当它需要数据时数据要怎么来的问题。
我们不追求严格的实时性和稳定性，这种事情还是需要工业界自己努力，我们只为了提供这样一个符合现代Robot AI系统的统一接口，使得上层的functionality是与平台无关的（但比如说有一些算法在实时性通信时满足不了实时性需求，用不了那是另说）。
当我们封装的通信接口足够多之后，结合实际需求（特别是服务业，家用场景），会定义一个通信标准（protocol），希望这套标准能使后来的机械臂生产厂商按照这个标准来开发通信程序（或者直接适配）。
概念设计： 上图中，我只列出了几个核心的functionality，其他的例如动力学辨识，calibration等，就没有包含在内。
目前我们围绕manipulator开发，但之后会拓展到mobile manipulator。
 因为实践中写着写着把原定于在第二期才做的部分内容也放到第一期里了，因此需要重新梳理一下接下来需要做的事情。
 一期计划（2020.6.22~2020.8.31）（07.29 update）  本体硬件平台的搭建和调试  在一期，我们将会引入两台机器人，包括UR5，和Franka。两台机器人都将分别完成其从硬件，到基本通信，到仿真环境的配置。   RobotFlow  Environment（08.09）：  兼容learning和descriptive task中的环境定义方式 支持从simulation，至少支持pybullet或mujoco中的一种 支持真实sensor中加载world的方式（需RFlib中第三视角标定完成）   Perception（08.02）：  MMDet的架构 YOLOv3 YOLOv4 YOLOv4-Tiny YOLOv3-USD YOLOv4-USD YOLOv4-Tiny-USD DenseFusion 6-Pack (08.09)   Robots（08.09）：  整理好格式，可以被加载入world中   Motion：  接入moveit，写好相关wrapper（08.09） 不依赖moveit的motion驱动（RFLib）, 写好相关wrapper（08.17）   Controller：  为UR5封装好基本的驱动（08.09） 为Franka封装好基本的驱动（08.17）   Message Pool Wrapper（08.31）：  不断迭代更新   Instruction：  加入对于goal描述的instruction（08.</description>
    </item>
    
    <item>
      <title>Conda是怎么搞坏你的编译的</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/conda%E6%98%AF%E6%80%8E%E4%B9%88%E6%90%9E%E5%9D%8F%E4%BD%A0%E7%9A%84%E7%BC%96%E8%AF%91%E7%9A%84/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/conda%E6%98%AF%E6%80%8E%E4%B9%88%E6%90%9E%E5%9D%8F%E4%BD%A0%E7%9A%84%E7%BC%96%E8%AF%91%E7%9A%84/</guid>
      <description>Conda是怎么搞坏你的编译的 今天的文章主要讨论一下用conda影响系统路径的几种方式，以后编译一些库的时候大家可以注意一下。
 最简单能处理的情况，当编译需要的python指向了conda的python  把conda从环境变量中去掉，新版的conda通常deactivate掉conda env即可。 把/usr/bin下的python，也就是系统自带的python，export到环境变量，确认在bash里敲python或者python3是默认安装的python   稍微麻烦的情况，编译时某些库，引用了conda里的安装包，这里有两种情况：  一种是你可以用conda的；一种是你自己准备了这些库，不想用conda的，通常是因为它的库没有安装完整（比如cuda只有一个runtime，没有nvcc）  前者如果只涉及到一个conda环境的时候，没关系直接用。但如果有多个环境的时候就会有问题。 后者需要改路径，改路径要么直接改CMakelist文件，要么通过gui版的cmake来改。     最麻烦的情况，CMakelist没写好，导致使用的python或其他包的路径在conda和系统路径下反复横跳。  如果处理不了，老老实实删conda    简评 大部分情况下，conda还是挺好用的，不过如果遇到一些意料之外的问题，还是优先考虑一下是不是路径被污染了。</description>
    </item>
    
    <item>
      <title>ROS Melodic支持python3</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/ros-melodic%E6%94%AF%E6%8C%81python3/</link>
      <pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/ros-melodic%E6%94%AF%E6%8C%81python3/</guid>
      <description>ROS melodic支持python3 我们后来发现python2和python3是可以直接通信的，所以这一个兼容性的问题暂时不是很大了。关于MoveIt我们也可以用C++去调里面的库。
背景 我们知道ROS1系列都是基于python2的，从Noetic开始（对应Ubuntu 20.04）能原生支持python3，因为2020年1月开始python的社区不再支持python2。
但稍早一些的版本，还是基于python2的，这样如果我们想构建一个与通信架构无关的机器人应用工具包（比如robotflow），那还是要放在python3的环境下进行的。 鉴于现在ROS1拥有比较完整的生态，ROS2还有很多bug，我们还是尽可能适配ROS1。
考虑目前最后一个python2的ROS1版本，melodic，其实它内部已经支持了python3，只不过pre-build的还是python2而已。因此，我们需要重新编译melodic。
在网上找了很多方案，最后按照如下步骤，成功完成melodic python3的编译安装。
Installation 我测试的时候是在虚拟机上，全新安装的Ubuntu 18.04的基础上做以下步骤的。所以前面有几步可能没有什么用，不过对于之前有安装过其他版本的情况，也不想重新安装的情况下，还是有点用的。
# ensure there are no ros packagessudo apt-get remove --autoremove ros-*# 添加ros的源，否则下面会有几个包装不了# check for updatessudo apt update# ensure /etc/ros removalsudo rm -rf /etc/ros/# install the python3 librariessudo apt install -y python3 python3-dev python3-pip build-essential# Remove python2sudo apt purge -y python2.7*# link python -&amp;gt; python3sudo ln -s /usr/bin/python3 /usr/bin/python# Same for pipsudo ln -s /usr/bin/pip3 /usr/bin/pip# install the ros dependenciessudo -H pip3 install rosdep rospkg rosinstall_generator rosinstall wstool vcstools catkin_tools catkin_pkg# initialize catkin build environmentsudo rosdep init &amp;amp;&amp;amp; rosdep update# create catkin workspacemkdir -p ~/ros_catkin_ws/src &amp;amp;&amp;amp; cd &amp;quot;$_/.</description>
    </item>
    
    <item>
      <title>一文搞懂相机模型</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E7%9B%B8%E6%9C%BA%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Fri, 17 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E7%9B%B8%E6%9C%BA%E6%A8%A1%E5%9E%8B/</guid>
      <description>一文搞懂相机模型 背景 相机模型是2D和3D沟通的桥梁，在2D-&amp;gt;2.5D, 2.5D-&amp;gt;3D, 2D-&amp;gt;3D, 3D-&amp;gt;2D等场合中都会用到它。 虽然它道理比较简单，但随之衍生出了很多工程技巧，稍不注意还是很容易出问题。一旦出问题，不搞懂原理的情况下就很难debug了。
基本概念 小孔成像和照相机成像 讲道理，小孔成像和照相机成像的原理是不一样的，小孔成像是基于光沿直线传播，成像条件很苛刻。现实中的照相机是采用透镜成像的原理，用凸透镜汇聚光，成像质量取决于孔径（aperture）和透镜质量。
那么我们为什么拿小孔成像的原理来分析透镜成像的相机模型呢？简单来说，它是真实成像的一阶近似，一般我们知道高阶的分量在一定情况下可以忽略。我们稍后聊distortion的时候，会有一个更直观的认识。
所以，不是小孔成像这个模型就很对了，只是它大概对了。
真实的相机中它没办法描述的情况，包括但不限于：
 geometric distortion 失焦造成的blur 像素的离散性  尽管如此，在大部分的情况下我们不用考虑这些问题，所以用小孔成像的模型就挺好了。
针孔相机（pinhole camera）建模 针孔相机模型如图所示：
这里涉及三个转换，真实世界中的一个点 $(x^w, y^w, z^w)$ ，在相机中的坐标 $(x, y, z)$ ，从相机坐标系，投到像平面坐标系 $(x&amp;rsquo;, y&amp;rsquo;)$，从像平面坐标系到像素平面坐标系 $(u,v)$。
那么具体来说，这是一个怎样的流程呢？
  世界坐标系到相机坐标系
世界坐标系可以说是这些坐标系里最不make sense的了，问题在于，这个坐标是谁定的？原点在哪里？ 这个问题很难用一个明确的词来回答，因为它就不是直接定义的，而是间接定义的。
从世界坐标系到相机坐标系，其转移公式是通过相机外参矩阵$[R, t]$，这个转移是这样进行的：
$$ \begin{bmatrix} x \\ y \\ z \\ 1 \end{bmatrix} = \begin{bmatrix}R &amp;amp; t \\ 0 &amp;amp; 1\end{bmatrix} \begin{bmatrix} x^w \\ y^w \\ z^w \\ 1\end{bmatrix} $$</description>
    </item>
    
    <item>
      <title>EinScan Pro 2X 2020版白平衡校准失败原因与方案</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/einscan-pro-2x-2020%E7%89%88%E7%99%BD%E5%B9%B3%E8%A1%A1%E6%A0%A1%E5%87%86%E5%A4%B1%E8%B4%A5%E5%8E%9F%E5%9B%A0%E4%B8%8E%E6%96%B9%E6%A1%88/</link>
      <pubDate>Tue, 07 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/einscan-pro-2x-2020%E7%89%88%E7%99%BD%E5%B9%B3%E8%A1%A1%E6%A0%A1%E5%87%86%E5%A4%B1%E8%B4%A5%E5%8E%9F%E5%9B%A0%E4%B8%8E%E6%96%B9%E6%A1%88/</guid>
      <description>问题描述：  问题设备：EinScan-Pro 2X 2020 问题版本：ExScanPro-V3.5.0.5 问题现象：相机标定正常；白平衡标定一直失败 问题分析：白平衡采集的图像过亮 临时解决方案：降低白平衡时候纹理相机增益（配置文件cameraGain_tex_cali修改为55）  具体操作步骤  到ExScanPro软件的安装目录下面，\path\to\ExScanPro\res(最后这个res是实际路径) 打开Config.xml，搜索cameraGain_tex_cali，将这个地方对应的参数改为55（默认64）  </description>
    </item>
    
    <item>
      <title>open-mmlab contribute 的 workflow</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/open-mmlab-contribute-%E7%9A%84-workflow/</link>
      <pubDate>Mon, 06 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/open-mmlab-contribute-%E7%9A%84-workflow/</guid>
      <description>open-mmlab contribute 的 workflow 提交 PR 前，contributor-side 的准备工作 参考资料：https://github.com/open-mmlab/mmdetection/blob/master/.github/CONTRIBUTING.md
What kind of contributions? All kinds of contributions are welcome, including but not limited to the following.
 Fixes (typo, bugs) New features and components  Workflow  fork and pull the latest mmdetection checkout a new branch (do not use master branch for PRs) commit your changes create a PR  Note
 If you plan to add some new features that involve large changes, it is encouraged to open an issue for discussion first.</description>
    </item>
    
    <item>
      <title>一文看懂PDDL</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82pddl/</link>
      <pubDate>Mon, 06 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82pddl/</guid>
      <description>一文看懂PDDL 背景 Planning是机器人运动的重要指导，为了看看各家planning算法在实际中的作用，学术界就搞了个International Planning Competition (IPC)比赛，这个比赛从1998年第一届开始，每两年一届，中间偶尔跳票，延续至今。
那么搞比赛，就希望能标准化task（benchmark问题）的描述，因此，开发出了PDDL（“Planning Domain Definition Language”）这个语言。随着比赛的进行，PDDL也在不断的改版，从1.0到3.1，中间也有很多变体。
PDDL有点类似SQL，它在语言里定义了很多规范，但很多实现并不是都支持所有的规范。大家主要支持的是STRIPS。但和SQL不同的是，这个语言因为暂时没有那么大的商业价值，所以几乎没有一个实现能保证它是完全按照规范来的，所以偶尔会有一些奇怪的语法要求（这也和部分语法规范含糊有关）。
如果我们之后要写自己的实现，那么就有必要了解一下这门语言发展到现在规范里包含了哪些内容，以及常见的语法。简单来说，就是看看它究竟能做什么？
PDDL简介 PDDL把一个任务规划问题拆解成两个部分，domain和problem。
Domain描述  domain-name requirements object-type hierarchy constant objects predicates actions  parameters preconditions effects  conditional (when-effects)      Problem描述  problem-name objects initial conditions goal-states  各版本的演进  1.0和2.0 (Wiki上也说是1.2)：确定了基本框架 2.1：  引入了数值表达，可以建模non-binary的资源，比如time，weight等。 引入了plan metric用来度量plan，用于支持utility-driven（换句话说就是plan的目标实现是一回事，达成这个目标的路径经不经济是另一回事） action从符号，变成可以持续的，连续的action。换句话说就是有连续的变量来描述它了。   2.2：  引入了derived predicates：如果A，则B；如果B，则C -&amp;gt; 如果A，则C 引入了timed initial literal：用于记录一些提前知道的，在某个时间点会发生的facts，比如 at 9 (shop-open)   3.</description>
    </item>
    
    <item>
      <title>Franka Emika Panda电脑安装配置指南</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/franka-emika-panda%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/</link>
      <pubDate>Sun, 05 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/franka-emika-panda%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/</guid>
      <description>本文主要参考该指南。
Requirements  一台用不上CUDA的电脑 Ubuntu 18.04 + ROS Melodic  系统装完请优先装real-time kernel，确定安装成功后再安装别的    安装real-time kernel 这个跟系统调度有关系，简单来说，需要把操作系统变成“实时响应”操作系统，franka对一个control流程的响应时间要求很高（&amp;lt;1ms）。因此，需要打上real-time priority的补丁。
这个补丁不是给正在运行的kernel打，而是在kernel还没安装上之前打。所以流程是这样的，首先到这个列表看看哪些版本的kernel有rt补丁，然后到这个地方下载对应版本的kernel。有人说这里rt补丁和kernel版本不一定对应，但我觉得对应是比较稳妥的。以5.6.17为例。
下载kernel并打好补丁  首先安装一些必要的程序  sudo apt-get install build-essential bc curl ca-certificates fakeroot gnupg2 libssl-dev lsb-release libelf-dev bison flex liblz4-tool  下载补丁  curl -SLO https://mirrors.edge.kernel.org/pub/linux/kernel/v5.x/linux-5.6.17.tar.xz curl -SLO https://mirrors.edge.kernel.org/pub/linux/kernel/v5.x/linux-5.6.17.tar.sign curl -SLO https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.6/patch-5.6.17-rt10.patch.xz curl -SLO https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.6/patch-5.6.17-rt10.patch.sign sign文件是用来检查文件完整性的，keyserver经常连不上，所以不检查也行。
 解压缩  xz -d linux-5.6.17.tar.xzxz -d patch-5.6.17-rt10.patch.xz 编译kernel  tar xf linux-5.6.17.tarcd linux-5.</description>
    </item>
    
    <item>
      <title>HTC vive安装&#43;Noitom手套完整配置流程</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/htc-vive%E5%AE%89%E8%A3%85&#43;noitom%E6%89%8B%E5%A5%97%E5%AE%8C%E6%95%B4%E9%85%8D%E7%BD%AE%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Fri, 03 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/htc-vive%E5%AE%89%E8%A3%85&#43;noitom%E6%89%8B%E5%A5%97%E5%AE%8C%E6%95%B4%E9%85%8D%E7%BD%AE%E6%B5%81%E7%A8%8B/</guid>
      <description>Requirements  支持Windows系统（Win10）的电脑，笔记本，台式均可  笔记本需要4个USB口，1个HDMI口，所以至少需要一个扩展USB口 SteamVR对显卡有一定的要求，请至少准备1060或同算力以上的显卡 安装steam  在steam上安装SteamVR   安装Unity 2017.1.0f3+   HTC vive VR设备一套（零件太多不一一例举） Noitom Hi5标准版手套一副 5号电池一对  HTC VIVE 安装流程   定位场
 本环节需要：  两根支架 两个定位器 两个定位器各自的电源 插排（optional）   安装流程：  支架上一共有四个旋钮，顶端有一个螺丝，新拆的情况下，螺丝有螺帽，拆掉即可。熟悉一下四个旋钮，旋转后哪些部位可动。接下来对这四个旋钮将按照自上而下，命名为1号，2号，3号和4号。 把支架腿往外掰，支架底部三角架张开合适的角度，拧紧4号旋钮 把定位器旋紧在顶部螺丝处，定位器的接口如图，不要拧错了口。  定位器屏幕那一面朝下30°或45°，拧紧1号旋钮 依次拧松2号，3号旋钮，把对应的杆拉出到最大 两根支架对角线放置，如图  插上定位器的电源线      头盔连接电脑
 本环节需要：  串流器 HTC vive头盔 HDMI线 USB线 串流器电源线 插排（optional）   安装流程  串流器上有一端是PC端，一端是VR端，根据提示把各个线接好即可。如图  如果是台式机，要注意电脑这边的接口最好是在独显附近。 电脑开机（如果已开机可以继续），关掉所有杀毒软件，包括但不限于360，鲁大师，腾讯管家，火绒等等   安装Steam 安装SteamVR    头盔和手柄校准</description>
    </item>
    
    <item>
      <title>机器搬到新地方配置网络连接</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/%E6%9C%BA%E5%99%A8%E6%90%AC%E5%88%B0%E6%96%B0%E5%9C%B0%E6%96%B9%E9%85%8D%E7%BD%AE%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/</link>
      <pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/%E6%9C%BA%E5%99%A8%E6%90%AC%E5%88%B0%E6%96%B0%E5%9C%B0%E6%96%B9%E9%85%8D%E7%BD%AE%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/</guid>
      <description> 想办法进入路由器管理页面  有可能这一步会比较麻烦，可能需要装宽带的人的指导   设置静态ip地址，该地址是这台服务器在内网里的地址，通常是192.168开头 设置端口转发，假如端口号是24000，可以设置24000~24999转发到服务器上 可能需要重启服务器 设置ssh  安装 sudo apt install ssh 配置 vim /etc/ssh/sshd_config 把port号改了 sudo systemctl restart ssh    </description>
    </item>
    
    <item>
      <title>Abstraction of Abstractions of ICRA 1984</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/abstraction-of-abstractions-of-icra-1984/</link>
      <pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/abstraction-of-abstractions-of-icra-1984/</guid>
      <description>Abstraction of Abstractions of ICRA 1984 AOA系列把历年各大机器人相关会议（ICRA，IROS，RSS，CoRL）和manipulation有关的文章的abstract提取出来，并做一个简评。大家如果对原文感兴趣，可去网盘查阅。
这个系列一方面是希望大家能尽快概览一遍过去的人都在做什么，一方面也是祛魅。
本期关注文章：31/74
太长不看 ICRA第一届会议起源于1984年，尽管如此，机器人在此之前就已经发展起来了，机械臂的基本硬件设计，从第一版到现在没有根本性的区别。适用于机械臂的planning的经典算法，早在这届会议之前就被提出Lozano-Perez79,Lozano-Perez81。 因此这届会议，比IROS的第一届会议（88年）要早，但仍不是机器人research的开端。我没有刻意去考证溯源，就姑且还是从第一届ICRA开始回顾机器人这近40年的发展。更早的历史和基础信息大家可以通过机器人学的课程获知，推荐两门公开课国立交通大学, 斯坦福公开课。
很有意思的是，尽管早期的系统相对比较简陋，各方面技术都不成熟。但机器人界要研究什么样的问题，基本上都已经出来了，可以说这么多年来，除了硬件软件更成熟，从思想层面很难说有什么本质上的变化。这会导致一个很直观的感觉就是，看着过去的文章，如果被标题唬住了，会觉得什么东西都没有做头了。
所以对于Robotics相关的research，不要问“这个idea前人没想过吗？”，因为前人肯定想过，关键在于他们做得怎么样。
 各track分类是我自己分的，难免有错漏。机器人的方向很多，我下面说一下哪些方向是我没有关注的：
  关于如何造机器人的，这部分topic涉及基本机器人学，比如inverse kinematics，dynamics，以及它们在仿真中的计算；还有硬件上的，如何造传感器，消除延迟，震动等。尽管我们不造机器人或者机械手，但是我们应该意识到，机器人能做多大的事，归根结底还是要取决于硬件的能力的。 关于传感器，我们严格区分multi-modal的话题和造传感器的文章。前者可以拧出来看看，后者就算了。 关于locomotion的话题比较纠结，因为很多机械臂的motion planning是退化到点（小车）来思考的，而且manipulation里面有一个交叉方向是mobile manipulator（也包括humanoid），现在还是有人关注的。但出于珍惜生命考虑，我暂时还是先不管了，感兴趣的同学可以日后survey。无人车属于locomotion的分支。 Robot Vision方向是我们比较熟悉的，因此除非一些想法特别有意思，否则我也不提了。 Robot learning的概念很晚，所以早期是不会有我们现在所谓robot learning的东西。等到这个概念出现的时候，会单独讨论一下。 关于Simulation，以前的simulation的文章放到现在大多被集成在一个个的库里了，这个放现在可能就是机器人学的最终大作业，所以我对此类文章也不专门记录，而且做这一块的核心主力应该在CG圈子。simulation2real是一个直到现在都很重要的课题，不过一般是归属于robot learning的框架。 工业级大型系统。我感觉在robotflow的项目周期里能考虑到两手合作就不错了，再大型的系统没必要现阶段考虑。  Robotics System  NNS A Lisp-based environment for the integration and operating of complex robotics systems  用于flexible assembly cell上的机器人系统，flexible assembly cell是什么google图片一下就知道。   A robust natural language interface to a robot assembly system  一套用自然语言和机器人交互的系统，需要包含几个特点：1. 自然语言的命令和low-level操作的关系；2.</description>
    </item>
    
    <item>
      <title>GraspIt安装踩坑经验</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/graspit%E5%AE%89%E8%A3%85%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/</link>
      <pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/graspit%E5%AE%89%E8%A3%85%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/</guid>
      <description>GraspIt安装踩坑经验 基本流程 GraspIt安装的基本流程可以按照这里的指示依次安装相应的依赖项、克隆Github仓库后手动编译安装。
错误提示 若cmake时出现&amp;rdquo; A required library with BLAS API not found. Please specify library location.&amp;quot;，或执行&amp;quot;make -j5&amp;quot;时出现&amp;quot;libgraspit.io: undefined reference to &amp;lsquo;daxpy_&#39;&amp;ldquo;等一系列&amp;quot;undefined reference to&amp;quot;的报错，可以尝试参考这里执行&amp;quot;sudo apt-get install libatlas-base-dev&amp;quot;后重新编译。
Qt版本问题 GraspIt是一个比较老的包，但暂时还没办法被替代，它只支持Qt4，而新的ROS已经支持到Qt5了，因此在安装过程中可能会有Qt版本的冲突。为了解决这个问题，我们常规的ROS版本设定是ROS1的kinetic，所以只能在ubuntu 16.04的机器上跑。</description>
    </item>
    
    <item>
      <title>RobotFlow Task Zoo</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/robotflow-task-zoo/</link>
      <pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/robotflow-task-zoo/</guid>
      <description>RobotFlow Task Zoo 本文主要收集主流实验中的manipulation task，并在最后试图让这些task从概念层面总结一下（某种意义上也是meta learning），由此分析出当前task定义的范围和下一步可能的发展。
眼下的manipulation related benchmark tasks总结 主要参考的文章有meta-world, RLBench, surreal
各任务具体的任务描述见文末。
首先，我们先把各benchmark里的task统一地总结起来。
关于各primitive primitive分两种，接触型primitve和运动型primitve。这里假定完成接触型primitive后手指和物体在一定程度上可以认为是相对静止的。
 grasp：接触型，单指“夹”这个动作，grasp有三个参数，一个是approach pose，一个是物体上的抓点，一个是施加的力。仿真问题一般不考虑力，但为了描述完整还是放这儿。决定这三个参数的叫grasp planner。 push：接触型，有三个参数，一个是approach pose，一个是push type（有用指侧推，有用指尖推，也有两指并拢推），一个是力。决定这三个参数的叫push planner。 move：运动型，是指手臂上的运动，无论是带物体还是不带物体。move的轨迹主要来自plan，约束是planner综合当前的可运动空间（避障）和物体的knowledge，以及对task的理解（物体和物体之间的关系对task的作用）考虑的，随着任务越多需要考虑的越复杂，不过这个是planner的问题，对于move来说它只用接受关于trajectory的指令。  reach是所有任务第一步都要做的，所以在动作序列里，除了只做reach操作以外的，都去掉了reach 常见的特殊move轨迹有：  rotate slide hit pour 铲     insert：运动型，这个动作包含peg in hole和hole out peg。理论上如果一切都很准，那么直接move就完事了，但之所以把insert拧出来，是因为解决距离洞口的误差是这个primitive的精髓所在，有点后处理的意思。  单纯任务    动作序列 任务名称 考虑物-物/环境关系     move reach; reach with wall    grasp -&amp;gt; move turn on faucet; turn off faucet;turn dial; pull handle;turn on faucet; turn off faucet;turn dial; pull handle;get coffee; pull handle side;basketball; pull with stick; disassemble nut; hammer;slide plate side; retrieve plate side;pull mug; unplug peg; close window; open window; open door; open drawer;beat the buzz; change clock;hockey; open fridge;open microwave; open oven;open wine bottle; pick and lift;pick up cup; play jenga;pour from cup to cup; scoop with spatula;straghten rope; sweep to dustpan;take umbrella out of umbrella stand; take usb out of computer;turn oven on; turn tap; unplug charger;water plants; wipe desk √   grasp -&amp;gt; move -&amp;gt; release stack; unstack; place onto shelf;pick &amp;amp; place; open box; close box; pick bin; get ice from fridge; meat off grill; meat on grill;move hanger; phone on base;place hanger on rack; put books on bookshelf;put bottle in fridge; put groceries in cupboard;put item in drawer; put knife on chopping board;put money in safe; put plate in colored dish rack;put rubbish in bin; put umbrella in umbrella stand;remove cups; setup checkers;set the table; stack cups; stack wine; take frame off hanger;take lid off saucepan; take item out of drawer;take money out safe; take off weighing scales;take plate off colored dish rack; take toilet roll off stand;weighing scales √   grasp -&amp;gt; move -&amp;gt; insert insert peg side; hang frame on hanger;hannoi square; insert usb in computer;place cups; place shape in shape sorter;plug charger in power supply; put knife in knife block;put toilet roll on stand; √   push -&amp;gt; move sweep; push; push back; press handle side; press handle;press button top; press button;lock door; unlock door; press switch    push -&amp;gt; move push with stick; sweep into hole; push mug; slide plate;soccer; retrieve plate; close drawer; close door; close/open box2;close fridge; close/open grill;close laptop lid; close microwave;lamp off; lamp on;toilet seat down; toilet seat up √    复合任务    任务名称 组合     press button wall reach with wall + press botton   press button top w/ wall reach with wall + press botton top   push with wall push + reach with wall   pick &amp;amp; place w/ wall pick &amp;amp; place + reach with wall   block pyramid stack * N   change channel pick &amp;amp; place + press botton   TV off pick &amp;amp; place + press botton   TV on pick &amp;amp; place + press botton   close door2 close door + press handle side   close jar pick &amp;amp; place + change clock   empty container pick &amp;amp; place * N   empty dishwasher open door + press handle + push back + pick &amp;amp; place   hit ball with queue pull handle + reach   light bulb in pick &amp;amp; place + change clock   light buib out change clock + pick &amp;amp; place   open door2 press handle + open door   open jar change clock + pick &amp;amp; place   open window2 change clock + push   put shoes in box open box2 + pick &amp;amp; place   put tray in oven open oven + pick &amp;amp; place   screw nail insert peg side + change clock   slide cabinet open and place cups open window + pick &amp;amp; place   solve puzzle pick &amp;amp; place * N   take cup out from cabinet open window + pick &amp;amp; place   take shoes out of box open box2 + pick &amp;amp; place   take tray out of oven open oven + pick &amp;amp; place    双手任务    任务名称 左手 右手     bimanual lifting lift lift   bimanual peg-in-hole insert peg side grasp    简评当前设计的benchmark task 如上所述，我把目前的152种benchmark task根据primitive的序列分成6大类，涉及到的primitive只有4种。我们可以从中得到几点启示：</description>
    </item>
    
    <item>
      <title>杜绝 tmux 中 conda 环境错乱之一劳永逸办法</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/%E6%9D%9C%E7%BB%9Dtmux%E9%87%8Cconda%E7%8E%AF%E5%A2%83%E9%94%99%E4%B9%B1%E4%B9%8B%E4%B8%80%E5%8A%B3%E6%B0%B8%E9%80%B8%E5%8A%9E%E6%B3%95/</link>
      <pubDate>Sat, 20 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/%E6%9D%9C%E7%BB%9Dtmux%E9%87%8Cconda%E7%8E%AF%E5%A2%83%E9%94%99%E4%B9%B1%E4%B9%8B%E4%B8%80%E5%8A%B3%E6%B0%B8%E9%80%B8%E5%8A%9E%E6%B3%95/</guid>
      <description>杜绝 tmux 中 conda 环境错乱之一劳永逸办法 思路 永远禁止 conda 环境自动激活，每次到了 tmux 里面需要开始生产的时候才激活。笔者试验了几个月，发现腿也不痛了腰也不酸了，再也不用 which pip / which python 了！
情况一 如果使用的 conda 版本较老 （$&amp;lt;4.4$），那么很有可能 ~/.bashrc 文件中会有 conda activate 一行。把这行给注释掉。（一般是在文件的末尾）
情况二 如果使用的 conda 版本较新，很可能只需要一行命令就可以了：
conda config --set auto_activate_base false 效果 打开一个新的终端，发现提示符前不会再出现 (base) 字样，说明设置成功。
参考资料 https://stackoverflow.com/questions/54429210/how-do-i-prevent-conda-from-activating-the-base-environment-by-default</description>
    </item>
    
    <item>
      <title>手眼标定介绍与使用</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/</guid>
      <description>Robotic Hand-eye Calibration Workspace | Ubuntu 1804 &amp;amp; ROS Melodic Morenia |
This repo contains a eye-in-hand calibration tool (Cplusplus &amp;amp; ROS) in JD京东 GRASPING ROBOT CHALLENGE (News),
and the implements of my paper: Robotic hand-eye calibration with depth camera: A sphere model approach (PDF)
Inside /src there are 5 ROS packages:
  rgbd_srv
used by camera_driver.
  camera_driver
drive Intel® RealSense™ RGBD cameras in ROS.
(convert raw stream to ros sensor_msgs::Image)</description>
    </item>
    
    <item>
      <title>使用MoveIt控制UR5</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/%E4%BD%BF%E7%94%A8moveit%E6%8E%A7%E5%88%B6ur5/</link>
      <pubDate>Thu, 28 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/%E4%BD%BF%E7%94%A8moveit%E6%8E%A7%E5%88%B6ur5/</guid>
      <description>使用MoveIt控制UR5 MoveIt简介  MOVEit！是目前针对移动操作最先进的软件。 它结合了运动规划，操纵，三维感知，运动学，控制和导航的最新进展 它提供了一个易于使用的平台，开发先进的机器人应用程序，评估新的机器人设计和建筑集成的机器人产品 它广泛应用于工业，商业，研发和其他领域。 MOVEit！是最广泛使用的开源软件的操作，并已被用于超过65个机器人  该简介引用自MoveIt!入门教程-简介，详情见官方主页https://moveit.ros.org/。
预备知识 学习 http://wiki.ros.org/ROS/Tutorials 的Core ROS Tutorials &amp;ndash; 1.1 Beignner Level &amp;ndash; 5~8节，对ROS node, topic, service, roslaunch等基本概念有了解。
在RViz中操控UR5机器人 在带有Universal Robot的包的工作空间下，启动UR5的驱动程序。
roslaunch ur_modern_driver ur5_bringup.launch robot_ip:=IP_OF_THE_ROBOT [reverse_port:=REVERSE_PORT] 然后执行以下命令。该launch文件主要配置了对应于UR5的参数，并启动了MoveIt包中的程序节点。
roslaunch ur5_moveit_config ur5_moveit_planning_execution.launch 最后，执行如下命令来启动RViz，便可在图形界面RViz中可视化地操控机器人。
roslaunch ur5_moveit_config moveit_rviz.launch config:=true 使用代码运行MoveIt MoveIt提供了名为MoveItGroupInterface的类，它简洁易用地封装了MoveIt的主要功能，如：设定某joints position或end effector的position为目标，为此规划一个path；控制机械臂的运动；在场景中添加、删除物体，为机械臂attach、detach物体等。MoveIt是基于C++实现的，而这个interface支持C++、python、命令行三种语言的调用。
该教程以python为例来使用该MoveItGroupInterface，参考了官方文档 https://ros-planning.github.io/moveit_tutorials/doc/move_group_python_interface/move_group_python_interface_tutorial.html ，但由于官方文档中使用了panda机械手的仿真，而我们希望操控UR5，所以在代码中planning_group的名称应当从&amp;quot;panda_arm&amp;quot;改为&amp;quot;manipulator&amp;rdquo;；在设置joints position为goal时，要注意UR5的joint数目比panda的少一个。
按照官方文档中的示例编写了如下Python脚本，使用MoveItGroupInterface来控制机器人。可将该脚本放置在任意ROS package的scripts目录中，使用
chmod +x [python_script_name] 来将该脚本变为可执行程序，再通过rosrun来使用它。
rosrun [package_name] [python_script_name] 该脚本只是简单示例，可参阅MoveIt官方文档了解细节。
#!/usr/bin/env python import rospy import moveit_commander import sys import moveit_msgs.</description>
    </item>
    
    <item>
      <title>ROS和UR5配置文档及踩坑经验</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/ros%E5%92%8Cur5%E9%85%8D%E7%BD%AE%E6%96%87%E6%A1%A3%E5%8F%8A%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/ros%E5%92%8Cur5%E9%85%8D%E7%BD%AE%E6%96%87%E6%A1%A3%E5%8F%8A%E8%B8%A9%E5%9D%91%E7%BB%8F%E9%AA%8C/</guid>
      <description>ROS和UR5配置文档 如有遗漏及错误，欢迎补充指正。
ROS配置 ROS仅支持Linux系统。最新版本为ROS Melodic Morenia。直接按照 http://wiki.ros.org/cn/melodic/Installation/Ubuntu 进行安装。
若在下面这条命令时报错：
sudo rosdep init ERROR: cannot download default sources list from: https://raw.githubusercontent.com/ros/rosdistro/master/rosdep/sources.list.d/20-default.list Website may be down. 则可尝试 https://blog.csdn.net/weixin_43288910/article/details/105627358 的方法修改host文件解决。
安装完成后可根据 http://wiki.ros.org/cn/ROS/Tutorials/InstallingandConfiguringROSEnvironment 创建一个新的工作空间用于学习ROS的基础用法。每次启动新终端时需要使用source ~/catkin_ws/devel/setup.bash命令将工作空间加入ROS工作环境，或者使用echo &amp;quot;source ~/catkin_ws/devel/setup.bash&amp;quot; &amp;gt;&amp;gt; ~/.bashrc命令，每次启动新终端时就默认将工作空间加入ROS工作环境了。
教程中如果命令中遇到kinectic或groovy等字段，说明是老版本ROS的命令，将其替换为melodic即可。UR5机器人安装与配置
机器人硬件安装 机器人本体安装 机器人主要分为机械臂、示教盒、控制箱等部分。将基座放于空旷处以避免机械臂运动时打到墙壁等障碍物。将扇形铁片装在基座上，再将圆形铁片装在扇形铁片上，最后将机械臂装在圆形铁片上即可。若由于机械臂阻挡，某些位置螺丝不好拧，可将控制箱上的电源线插好，启动机器，操纵机械臂转动，再拧螺丝。
夹爪安装及使用 如果要安装夹爪等工具，将其用螺丝固定在机械臂末端并将夹爪上的带有五根针的数据线与控制箱上的带有五个孔数据线插在一起旋紧即可。开机后在面板上选择为机器人编程-安装设置-Gripper-Scan即可使用。如果Scan无反应，检查控制箱，确保红线插24v，黑线插0v，（任意24v，0v皆可）若脱落，则将所需黄色块拔出，将线插进相应孔并用螺丝刀拧紧，将黄色块装回，再测试。
机器人包安装及连接电脑 UR包安装教程 http://wiki.ros.org/universal_robots
UR5连接电脑及使用 UR5使用教程:
[http://wiki.ros.org/universal_robot/Tutorials/Getting%20Started%20with%20a%20Universal%20Robot%20and%20ROS-Industrial](http://wiki.ros.org/universal_robot/Tutorials/Getting Started with a Universal Robot and ROS-Industrial)
其中，连接电脑是通过以太网（简称网线）。用网线将电脑及控制箱连接起来，在机器人示教盒面板上选择设置机器人-网络-静态地址，并设置相关信息及电脑有线连接里的相关信息。电脑与机器人的IP地址前三个字段一样（代表处于一个网络中），最后一个字段不同即可（代表不同主机）。个人设置的机器人IP为192.168.1.102，电脑有线连接IP为192.168.1.103。子网掩码均为255.255.255.0。（如果是输位数则为24）网关为192.168.1.1。设置好后可尝试使用ping IP_OF_THE_ROBOT命令来测试连接状态。若能显示延迟则连接成功。
连接成功后，需启动UR的驱动。这里一共有三个版本。最老版的就是UR包自带的ur_driver，接着是要单独安装的ur_modern_driver，最新的是Universal_Robots_ROS_Driver，支持3.7以上版本的PolyScope。由于我们的UR5装的polyscope为3.4版本，因此使用ur_modern_driver https://github.com/ros-industrial/ur_modern_driver 。若根据教程启动驱动时报错，可根据报错信息及 在Ubuntu16.04下使用ur_modern_driver无法编译成功的解决方法 进行相应修改即可。
最后根据UR5使用教程，即可使用MoveIt及RViz可视化地操控机器人。</description>
    </item>
    
    <item>
      <title>如何批量从IEEE上下文章</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/%E5%A6%82%E4%BD%95%E6%89%B9%E9%87%8F%E4%BB%8Eieee%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AB%A0/</link>
      <pubDate>Sat, 23 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/%E5%A6%82%E4%BD%95%E6%89%B9%E9%87%8F%E4%BB%8Eieee%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AB%A0/</guid>
      <description>以前我们涉足的Vision相关的领域都是崇尚open access的，所以如果需要批量扫文章的时候，把整个会议拖库下下来是很容易的事情。但我们接下来会接触到机器人的领域，这个领域里很多文章版权都在IEEE手上。目前IEEE Xplore下着下着就会限制ip，所以如果需要批量化把一整个会议/期刊的文章都下下来的话，那么就需要费点事情了。
因为进入新领域，要快速入门，我只有一个笨办法，就是尽可能把所有相关文章遍历一遍。所以第一步需要把文章都收集起来。
FBI Warning 完整的把一个会议或者期刊的文章从IEEE上拖下来是违反使用条例Term of use的。所以我也不会在文中涉及具体的code，code请见网盘，或找文强要。
零星的几篇文章下载 通过学校的ip（在校园内，或者走VPN）直接去ieeexplore下载即可。
大批量(&amp;gt;100)文章下载 根据经验，在一次ip限制里，官方会允许你下载50篇左右的文章，因此，如果量不大的话，请直接走官方渠道，官方也提供一次下载十篇的批量化下载（在网页上找找就能看到啦）。
那么面对大批量的文章，要怎么做呢？
 用selenium + chrome，再通过xpath分析的方式，把网页中title，link都爬下来。因为这部分内容是完全公开的，所以没有任何限制。 使用requests，去请求刚刚爬下来的link，这个link是利用jsp动态获取pdf，所以需要用beautiful soup解析一下request link得到的内容，以得到pdf的地址。 因为用requests还是会被ban，所以最好是每50篇后让进程睡15分钟（经验值）  如果不想让进程sleep？ 因为每50篇就sleep 15分钟，那下得多的话还是要等很久。如果不想sleep，那么就不能走官方渠道。这时候就需要请出sci-hub了。 只需要在官方的链接，比如：https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=126246，前加上https://sci-hub.tw/即可。最后得到：https://sci-hub.tw/https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=126246
两个https看上去有点诡异，但绝对work。
注意，用sci-hub前缀，依然需要学校ip。下多了sci-hub也会封ip，不过它的封禁策略相对比较缓和，基本上等一天就没事了。如果不想等，把当前的校园网断开连接，多刷新几下，再重连，大概率就能继续work，如果还不行，就repeat几次。</description>
    </item>
    
    <item>
      <title>Minkowski安装过程中的一些坑</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/minkowski%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/</link>
      <pubDate>Sun, 19 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/minkowski%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/</guid>
      <description>Requirements and check methods  Ubuntu 14.04 or higher CUDA 10.1 or higher nvcc --version  pytorch 1.3 or higher python import torch torch.__version__  python 3.6 or higher gcc-7 or higher gcc -v g++ -v   Installation The Minkowski engine github page gives three ways to install: pip, anaconda, or on the system directly. Here I strongly recommand installing it using anaconda since our servers are managed based on anaconda environment.</description>
    </item>
    
    <item>
      <title>修改默认gcc版本</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4gcc%E7%89%88%E6%9C%AC/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4gcc%E7%89%88%E6%9C%AC/</guid>
      <description>网上有一些switch的方案，但配置起来比较麻烦，有可能不同步。 我们还是直接改路径，这样在编译的时候会稳定一点。 sudo apt install gcc-6 g++-6
sudo ln -s /usr/bin/gcc-6 /usr/local/bin/gcc
sudo ln -s /usr/bin/g++-6 /usr/local/bin/g++</description>
    </item>
    
    <item>
      <title>合理设置mkl，降低负载、提升性能</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/%E5%90%88%E7%90%86%E8%AE%BE%E7%BD%AEmkl%E9%99%8D%E4%BD%8E%E8%B4%9F%E8%BD%BD%E6%8F%90%E5%8D%87%E6%80%A7%E8%83%BD/</link>
      <pubDate>Fri, 31 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/%E5%90%88%E7%90%86%E8%AE%BE%E7%BD%AEmkl%E9%99%8D%E4%BD%8E%E8%B4%9F%E8%BD%BD%E6%8F%90%E5%8D%87%E6%80%A7%E8%83%BD/</guid>
      <description>背景 MKL 是英特尔提供的号称最快而且最多人使用的科学计算库。
公元 2020 年，大家常用的 numpy, scikit-learn, scipy, 甚至 mxnet 等 Python package 都已经默认使用 mkl编译。mkl 带来给我们带来了性能提升，而且并不需要我们改动 Python 代码，这固然是一件好事。然而，在日常使用过程中，我们也发现了一些意外。
MKL的缺点  Intel MKL 的默认策略其实比较复杂，可以简单地认为是尽可能使得全核心满载。
 这对于那些动辄好几小时的大矩阵运算来说当然非常好。然而，我们日常的 Work Load 可能就是几个小 numpy array 倒腾，不太需要 mkl 库来加速。特别是 dataloader 阶段，dataloader 本身就已经是多线程运行的了（num_workers 参数），如果每个线程在 mkl 的“帮助”下争抢全核心，很容易造成 Load Average 爆炸，算力被浪费在系统调度上，性能反而大大降低的现象。
不健康的情况   单个 Python 程序占满了整个 CPU，但是实际“利用率”（绿色部分）并不高，大量算力被浪费在了系统调度上 （橙色部分）。（24000 是双路 CPU，因此 2000% 的占用对应一整个 CPU）   单个 Python 程序被分散到几个核心上运行，但总负荷约为 100%，且系统调度占用比较高。这可能是单个线程 由于种种原因被操作系统不断地切换到不同核心运行，一般认为会影响性能。   解决方案  详情请见 How to set good environment variables for the Intel MKL library 一文，这里只搬运解决方法。</description>
    </item>
    
    <item>
      <title>如何使用XShell将tensorboard转发到本地浏览器</title>
      <link>http://mvig.sjtu.edu.cn/robotflow/article/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8xshell%E5%B0%86tensorboard%E8%BD%AC%E5%8F%91%E5%88%B0%E6%9C%AC%E5%9C%B0%E6%B5%8F%E8%A7%88%E5%99%A8/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>http://mvig.sjtu.edu.cn/robotflow/article/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8xshell%E5%B0%86tensorboard%E8%BD%AC%E5%8F%91%E5%88%B0%E6%9C%AC%E5%9C%B0%E6%B5%8F%E8%A7%88%E5%99%A8/</guid>
      <description>如何使用XShell将tensorboard转发到本地浏览器  设置隧道转发 右键单击会话项，选择属性   类别一栏选择“隧道” 点击添加 设置侦听端口与目标端口，这里尽量选择较大的数字像15555，避免使用太简单容易想到的数字，防止大家在服务器上冲突。侦听端口是本地的端口，目标端口是服务器端口。
设置完成后点击确定，然后重新连接服务器。
Tensorboard的使用  命令tensorboard &amp;ndash;logdir=/home/you/log &amp;ndash;port=15555 logdir是tensorboard文件所在位置；
文件通常名为类似events.out.tfevents.1569252962.nonews。这里通常只需要指定到目录即可，如果目录下有多个文件，就会在浏览器上同时显示，然后选择你所需要的即可。 port即为刚刚设置的目标端口，此时会被转发到你的主机上。
打开浏览器，访问localhost:15555（你刚刚指定的目标端口）</description>
    </item>
    
  </channel>
</rss>